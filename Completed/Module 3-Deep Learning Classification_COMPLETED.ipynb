{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop Description\n",
    "Understanding the questions posed by instructors and students alike plays an important role in the development of educational technology applications. In this intermediate level workshop, you will learn to apply NLP to one piece of this real-world problem by building a model to predict the type of answer (e.g. entity, description, number, etc.) a question elicits. Specifically, you will learn to:\n",
    "1. Perform preprocessing, normalization, and exploratory analysis on a question dataset,\n",
    "2. Identify salient linguistic features of natural language questions, and\n",
    "3. Experiment with different feature sets and models to predict the answer type.\n",
    "4. Use powerful pretrained language models to create dense sentence representations and apply deep learning models to text classification.\n",
    "\n",
    "The concepts will be taught using popular NLP and ML packages like SpaCy, Scikit Learn, and Tensorflow.\n",
    "\n",
    "This workshop assumes familiarity with Jupyter notebooks and the basics of scientific packages like numPy and sciPy. We also assume some basic knowledge of machine learning and deep learning techniques like CNNs, LSTMs, etc. Reference materials will be provided to gain a better understanding of these techniques for interested attendees.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Representation Learning to classify TREC question-classification text\n",
    "\n",
    "**Overview:** \n",
    "In this session we'll try to solve the TREC question-classification problem by using a few popular Deep Learning Algorithms.\n",
    "Concretely, we will use pre-trained Language Models to generate **representations(Embeddings)** for our input data and then classify these representations using a shallow neural network.\n",
    "We will examine the network architectures of **Universal Sentence Encoder(USE)** and **Bidirectional Encoder Representation from Transformers(BERT)** and touch upon the pros and cons of these architectures in classifying TREC question-classification data.\n",
    "\n",
    "### What you'll learn:\n",
    "- How to use **Keras** for Text classification\n",
    "- How to generate representations using pre-trained **Universal Sentence Encoder: USE**\n",
    "- How to tune and evaluate Deep Learning models \n",
    "- How to use **Tensorflow** for Text classification\n",
    "- How to use pre-trained Language Model **Bidirectional Encoder Representation from Transformers: BERT** for Text classification\n",
    "\n",
    "**Note:** We will be using the same dataset as the previous 2 sessions. Notebook links to the previous session are available [Module 2-Feature Extraction and Classification](Module 2-Feature Extraction and Classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Represenations:\n",
    "![dep_nobj-1](images/Word2Vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Representation\n",
    "![dep_nobj-1](images/SentenceEmbedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "The following two utility functions provide functionality that can be used across different models to inspect training metrics and performance. These will be used at a later point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# UNCOMMENT AND RUN THIS CELL ONLY IF USING COLAB #\n",
    "###################################################\n",
    "\n",
    "# !pip install bert-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matplotlib Plotting Import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Function to plot training accuracy/loss, validation accuracy/loss.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history: \n",
    "        Keras training history object. See: https://keras.io/callbacks/#history\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Keras Imports: USE Embedding Classification\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#Sklearn Utility Imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def generate_classification_report(model_path, label_encoder, test_features, test_labels, class_names=None):\n",
    "    \"\"\"\n",
    "    Function to generate SKLearn based multi class classification report\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path: Path to trained model.\n",
    "    label_encoder: Encoder used during label transformation\n",
    "    test_features: Features for test.\n",
    "    test_labels: Ground truth labels\n",
    "    class_names: Class names for the true and pred integer values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: sklearn.metrics.classification_report\n",
    "        MultiClass Classification Report.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pre-trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Predict labels for test features\n",
    "    preds = model.predict(test_features)\n",
    "    \n",
    "    # Since the model is trained to return a set of probabilities across the label set, \n",
    "    # we'll have to find the index of label set with the highest probability score.\n",
    "    preds_index = np.argmax(preds, axis=1)\n",
    "    \n",
    "    # Converting the predicted index into the original TREC based label\n",
    "    preds_labels = label_encoder.inverse_transform(preds_index)\n",
    "    \n",
    "    return classification_report(test_labels, preds_labels, target_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "First let's download the train and test data from Xin Li, Dan Roth, Learning Question Classifiers. COLING'02, Aug., 2002.\n",
    "    <https://cogcomp.seas.upenn.edu/Data/QA/QC/\">https://cogcomp.seas.upenn.edu/Data/QA/QC/>\n",
    "    \n",
    "We will store these data in Pandas DataFrames (and write them as .csv files) containing the following columns:\n",
    "- *question*: The question text\n",
    "- *processed_question*: The question as a SpaCy Doc object\n",
    "- *coarse_label*: The coarse-grained label (6 classes)\n",
    "- *label*: The fine-grained label\n",
    "\n",
    "Recall that in Module 1, we found that some questions were duplicated. Let's remove those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_trec_data(text):\n",
    "    \"\"\"\n",
    "    Convert the whitespace-delimited text format of TREC data to a Pandas\n",
    "    DataFrame, with the labels processed into fine- and coarse-grained\n",
    "    alternatives.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        The full text of the TREC data. Each line consists of the fine-grained\n",
    "        label (eg \"NUM:date\") followed by a space and the question text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Pandas DataFrame with three columns: 'question', 'label', and\n",
    "        'coarse_label'.\n",
    "\n",
    "    \"\"\"\n",
    "    data = [line for line in text.split('\\n') if line]\n",
    "    labels, questions = zip(*[line.split(' ', 1) for line in data])\n",
    "    coarse_labels = [label.split(':')[0] for label in labels]\n",
    "    df = pd.DataFrame({\"question\": questions,\n",
    "                       \"label\": labels,\n",
    "                       \"coarse_label\": coarse_labels})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'data' created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from os import path, mkdir\n",
    "\n",
    "train_url = \"https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\"\n",
    "test_url = \"https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\"\n",
    "\n",
    "data_dir_name = 'data'\n",
    "try:\n",
    "    mkdir(data_dir_name)\n",
    "    print(\"Directory '{}' created\".format(data_dir_name))\n",
    "except FileExistsError:\n",
    "    print(\"Directory '{}' already exists\".format(data_dir_name))\n",
    "    \n",
    "data = requests.get(train_url).text\n",
    "train_df = format_trec_data(data)\n",
    "\n",
    "data = requests.get(test_url).text\n",
    "test_df = format_trec_data(data)\n",
    "\n",
    "train_df.to_csv(path.join(data_dir_name, \"train.csv\"), index=False)\n",
    "test_df.to_csv(path.join(data_dir_name, \"test.csv\"), index=False)\n",
    "\n",
    "\n",
    "#\n",
    "# Dedupe from python module.\n",
    "#\n",
    "train_df = train_df.drop_duplicates(\"question\")\n",
    "test_df = test_df.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder\n",
    "<u>Reference Paper</u>: https://arxiv.org/abs/1803.11175<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html<br><br>\n",
    "**Universal Sentence Encoder (USE)** is a versatile sentence embedding model that convert sentences into vector representations. These vectors capture rich semantic information that can be used to train classifiers for a broad range of downstream tasks.\n",
    "\n",
    "![dep_nobj-1](images/USE.png)\n",
    "\n",
    "Note: USE can work on small multi sentence paragraphs.\n",
    "\n",
    "\n",
    "### High level steps for classifying text using pre-trained USE model: \n",
    "- Download Pre-trained USE Model from Tensorflow HUB<br>\n",
    "- Extract USE Repesentations for both train and test sets<br>\n",
    "- Define a the classification network architecture<br>\n",
    "- Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for USE Q&A classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process_text(input_text):\n",
    "    \"\"\"\n",
    "    Function to normalize text by applying NLP tranformations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text: String \n",
    "        Question text from the input sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String\n",
    "        pre-processed version of input string\n",
    "    \"\"\"\n",
    "    #Exercise: build multiple models based on diferrent pre-processing techniques.\n",
    "    #Un-Comment the below line to see if the model performance improves by introducing additional \n",
    "    #input_text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', input_text)\n",
    "    return input_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the raw question text and labels from the training and test dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_df['question'].to_list()\n",
    "features_test  = test_df['question'].to_list()\n",
    "labels_train   = train_df['coarse_label'].to_list()\n",
    "labels_test    = test_df['coarse_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-Process the text used for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process the text used for training and test\n",
    "features_train_processed = list(map(lambda x:pre_process_text(x), features_train))\n",
    "features_test_processed = list(map(lambda x:pre_process_text(x), features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The labels for the training and test set are in a string format (eg: ABBR, DESC etc). These labels need to be converted into a numerical set using [Scikit Learn's Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process labels for training\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels_train_tranformed = label_encoder.fit_transform(labels_train)\n",
    "labels_train_categorical = to_categorical(np.asarray(labels_train_tranformed))\n",
    "# Note: We do not have to \"fit\" the label encoder for the test set since they already have been fit on the trainset\n",
    "labels_test_transformed = label_encoder.transform(labels_test)\n",
    "labels_test_categorical = to_categorical(np.asarray(labels_test_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and load the pre-trained Universal Sentence Encoder from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "pre_trained_use_embed_model = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate sentence/phrase representations of the training and test text data using the above downloaded USE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_features_train = []\n",
    "embeddings_features_test = []\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings_features_train.append(session.run(pre_trained_use_embed_model(features_train_processed)))\n",
    "    embeddings_features_test.append(session.run(pre_trained_use_embed_model(features_test_processed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train = embeddings_features_train[0]\n",
    "question_embeddings_test = embeddings_features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition for USE Q&A classification\n",
    "\n",
    "We will use the [Keras Functional API Guide](https://keras.io/getting-started/functional-api-guide/#first-example-a-densely-connected-network) to build and train the USE Q&A classifier network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class QNAClassifier():\n",
    "    \"\"\"\n",
    "    Q&A classifier class using Keras framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name):\n",
    "        \"\"\"\n",
    "        Init function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_name: String\n",
    "            Name of the experiment. This will be used to name the model checkpoints.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #Exercise: Modify the below hyper parameters to create variations of the USE Q&A classifier model.\n",
    "        self.patience = 10\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.experiment_name = experiment_name\n",
    "        self.output_dir = 'models'\n",
    "        self.class_count = 6\n",
    "        self.model = None\n",
    "        \n",
    "        # Creating an output directory for the generated models.\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    \n",
    "    def train_vanilla_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        Simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(256, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        # Start Training\n",
    "        training_history = self.model.fit(embeddings_train, labels_train, \n",
    "                                          validation_data = (embeddings_test, labels_test),\n",
    "                                          epochs= self.epochs,\n",
    "                                          batch_size=self.batch_size,\n",
    "                                          callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history\n",
    "    \n",
    "    def train_vanilla_nn_cross_validated(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        K-Fold Cross validated simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        list of training history objects\n",
    "            Keras training history object. See: https://keras.io/callbacks/#history\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(64, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        \n",
    "        training_histories = []\n",
    "        counter = 0\n",
    "        \n",
    "        #Exercise: Experiment with different number of splits.\n",
    "        kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "        for train_index, test_index in kf.split(embeddings_train):\n",
    "            \n",
    "            X_train, X_test = embeddings_train[train_index], embeddings_train[test_index]\n",
    "            y_train, y_test = labels_train[train_index], labels_train[test_index]\n",
    "            \n",
    "            model_filename = self.output_dir + \"/\" + self.experiment_name + \"_fold{}\".format(counter)\n",
    "            checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                         monitor='val_acc', verbose=1,\n",
    "                                         save_best_only=True, mode='auto')\n",
    "        \n",
    "            # Start Training\n",
    "            training_history = self.model.fit(X_train, y_train, \n",
    "                                              validation_data = (X_test, y_test),\n",
    "                                              epochs= self.epochs,\n",
    "                                              batch_size=self.batch_size,\n",
    "                                              #Exercise: Add Tensorboard here\n",
    "                                              callbacks=[checkpoint, early_stopping])\n",
    "            \n",
    "            print(\"-----------------------------\\n\")\n",
    "            print(\"KSplit {} training complete\\n\".format(counter))\n",
    "            print(\"-----------------------------\\n\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            training_histories.append(training_history)\n",
    "        \n",
    "        return training_histories\n",
    "    \n",
    "    def train_tuned_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \n",
    "        \"\"\"\n",
    "        Tuned Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(128, activation='relu')(embedding_inputs)\n",
    "        # Added dropouts for regularization\n",
    "        # Exercise: Change the value of dropouts.\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        \n",
    "        # Start Training\n",
    "        training_history = model.fit(embeddings_train, labels_train, \n",
    "                                     validation_data = (embeddings_test, labels_test),\n",
    "                                     epochs= self.epochs,\n",
    "                                     batch_size=self.batch_size,\n",
    "                                     #Exercise: Add Tensorboard here\n",
    "                                     callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1029 17:43:51.722391 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1029 17:43:51.723466 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1029 17:43:51.726526 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1029 17:43:51.752485 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1029 17:43:51.774127 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1029 17:43:51.869182 140537078560576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1029 17:43:51.918712 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5381 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "5381/5381 [==============================] - 5s 936us/step - loss: 1.0491 - acc: 0.6980 - val_loss: 0.5111 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87800, saving model to models/USE_Embedding_Model.001-0.8780.hdf5\n",
      "Epoch 2/100\n",
      "5381/5381 [==============================] - 0s 86us/step - loss: 0.5434 - acc: 0.8106 - val_loss: 0.3933 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87800\n",
      "Epoch 3/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.4608 - acc: 0.8350 - val_loss: 0.3286 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87800 to 0.88400, saving model to models/USE_Embedding_Model.003-0.8840.hdf5\n",
      "Epoch 4/100\n",
      "5381/5381 [==============================] - 0s 85us/step - loss: 0.4274 - acc: 0.8420 - val_loss: 0.3339 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88400\n",
      "Epoch 5/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.4044 - acc: 0.8563 - val_loss: 0.3168 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88400 to 0.89000, saving model to models/USE_Embedding_Model.005-0.8900.hdf5\n",
      "Epoch 6/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.3933 - acc: 0.8589 - val_loss: 0.2996 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.89000 to 0.89200, saving model to models/USE_Embedding_Model.006-0.8920.hdf5\n",
      "Epoch 7/100\n",
      "5381/5381 [==============================] - 0s 82us/step - loss: 0.3806 - acc: 0.8632 - val_loss: 0.3004 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89200 to 0.89600, saving model to models/USE_Embedding_Model.007-0.8960.hdf5\n",
      "Epoch 8/100\n",
      "5381/5381 [==============================] - 0s 85us/step - loss: 0.3679 - acc: 0.8677 - val_loss: 0.2984 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89600\n",
      "Epoch 9/100\n",
      "5381/5381 [==============================] - 0s 89us/step - loss: 0.3587 - acc: 0.8675 - val_loss: 0.2961 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89600\n",
      "Epoch 10/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.3493 - acc: 0.8734 - val_loss: 0.2866 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89600 to 0.89800, saving model to models/USE_Embedding_Model.010-0.8980.hdf5\n",
      "Epoch 11/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.3419 - acc: 0.8785 - val_loss: 0.2761 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.89800 to 0.90600, saving model to models/USE_Embedding_Model.011-0.9060.hdf5\n",
      "Epoch 12/100\n",
      "5381/5381 [==============================] - 0s 86us/step - loss: 0.3320 - acc: 0.8814 - val_loss: 0.2808 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90600\n",
      "Epoch 13/100\n",
      "5381/5381 [==============================] - 0s 84us/step - loss: 0.3226 - acc: 0.8803 - val_loss: 0.2770 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90600\n",
      "Epoch 14/100\n",
      "5381/5381 [==============================] - 0s 87us/step - loss: 0.3115 - acc: 0.8876 - val_loss: 0.2861 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90600\n",
      "Epoch 15/100\n",
      "5381/5381 [==============================] - 0s 86us/step - loss: 0.3110 - acc: 0.8902 - val_loss: 0.2882 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90600\n",
      "Epoch 16/100\n",
      "5381/5381 [==============================] - 0s 88us/step - loss: 0.2985 - acc: 0.8904 - val_loss: 0.2746 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90600\n",
      "Epoch 17/100\n",
      "5381/5381 [==============================] - 0s 88us/step - loss: 0.2901 - acc: 0.8950 - val_loss: 0.2757 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90600\n",
      "Epoch 18/100\n",
      "5381/5381 [==============================] - 0s 83us/step - loss: 0.2802 - acc: 0.8974 - val_loss: 0.2722 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90600\n",
      "Epoch 19/100\n",
      "5381/5381 [==============================] - 0s 89us/step - loss: 0.2696 - acc: 0.9024 - val_loss: 0.2765 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90600\n",
      "Epoch 20/100\n",
      "5381/5381 [==============================] - 0s 88us/step - loss: 0.2624 - acc: 0.9045 - val_loss: 0.2680 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90600\n",
      "Epoch 21/100\n",
      "5381/5381 [==============================] - 0s 82us/step - loss: 0.2540 - acc: 0.9062 - val_loss: 0.2748 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.90600\n"
     ]
    }
   ],
   "source": [
    "# Train Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(use_embedding_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 1794 samples\n",
      "Epoch 1/100\n",
      "3587/3587 [==============================] - 4s 1ms/step - loss: 1.3435 - acc: 0.6610 - val_loss: 1.0305 - val_acc: 0.7235\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72352, saving model to models/USE_Embedding_CV_Model_fold0.001-0.7235.hdf5\n",
      "Epoch 2/100\n",
      "3587/3587 [==============================] - 0s 89us/step - loss: 0.8662 - acc: 0.7703 - val_loss: 0.7562 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72352 to 0.77648, saving model to models/USE_Embedding_CV_Model_fold0.002-0.7765.hdf5\n",
      "Epoch 3/100\n",
      "3587/3587 [==============================] - 0s 98us/step - loss: 0.6679 - acc: 0.8012 - val_loss: 0.6324 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77648 to 0.80045, saving model to models/USE_Embedding_CV_Model_fold0.003-0.8004.hdf5\n",
      "Epoch 4/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.5668 - acc: 0.8166 - val_loss: 0.5650 - val_acc: 0.8010\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80045 to 0.80100, saving model to models/USE_Embedding_CV_Model_fold0.004-0.8010.hdf5\n",
      "Epoch 5/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.5071 - acc: 0.8274 - val_loss: 0.5279 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80100 to 0.81048, saving model to models/USE_Embedding_CV_Model_fold0.005-0.8105.hdf5\n",
      "Epoch 6/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.4681 - acc: 0.8322 - val_loss: 0.5082 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.81048 to 0.81661, saving model to models/USE_Embedding_CV_Model_fold0.006-0.8166.hdf5\n",
      "Epoch 7/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.4435 - acc: 0.8417 - val_loss: 0.4956 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81661 to 0.82330, saving model to models/USE_Embedding_CV_Model_fold0.007-0.8233.hdf5\n",
      "Epoch 8/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.4256 - acc: 0.8500 - val_loss: 0.4875 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.82330\n",
      "Epoch 9/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.4107 - acc: 0.8539 - val_loss: 0.4790 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.82330 to 0.82497, saving model to models/USE_Embedding_CV_Model_fold0.009-0.8250.hdf5\n",
      "Epoch 10/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3976 - acc: 0.8559 - val_loss: 0.4719 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82497 to 0.82553, saving model to models/USE_Embedding_CV_Model_fold0.010-0.8255.hdf5\n",
      "Epoch 11/100\n",
      "3587/3587 [==============================] - 0s 102us/step - loss: 0.3906 - acc: 0.8609 - val_loss: 0.4714 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.82553\n",
      "Epoch 12/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.3815 - acc: 0.8634 - val_loss: 0.4711 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82553\n",
      "Epoch 13/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3743 - acc: 0.8665 - val_loss: 0.4674 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.82553 to 0.83055, saving model to models/USE_Embedding_CV_Model_fold0.013-0.8305.hdf5\n",
      "Epoch 14/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.3684 - acc: 0.8670 - val_loss: 0.4743 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.83055\n",
      "Epoch 15/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3636 - acc: 0.8670 - val_loss: 0.4695 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.83055\n",
      "Epoch 16/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.3585 - acc: 0.8679 - val_loss: 0.4691 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.83055\n",
      "Epoch 17/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.3526 - acc: 0.8732 - val_loss: 0.4692 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.83055\n",
      "Epoch 18/100\n",
      "3587/3587 [==============================] - 0s 94us/step - loss: 0.3481 - acc: 0.8718 - val_loss: 0.4704 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.83055\n",
      "Epoch 19/100\n",
      "3587/3587 [==============================] - 0s 98us/step - loss: 0.3441 - acc: 0.8740 - val_loss: 0.4654 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.83055\n",
      "Epoch 20/100\n",
      "3587/3587 [==============================] - 0s 114us/step - loss: 0.3409 - acc: 0.8754 - val_loss: 0.4716 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.83055\n",
      "Epoch 21/100\n",
      "3587/3587 [==============================] - 0s 95us/step - loss: 0.3344 - acc: 0.8784 - val_loss: 0.4641 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.83055 to 0.83389, saving model to models/USE_Embedding_CV_Model_fold0.021-0.8339.hdf5\n",
      "Epoch 22/100\n",
      "3587/3587 [==============================] - 0s 102us/step - loss: 0.3341 - acc: 0.8779 - val_loss: 0.4646 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.83389\n",
      "Epoch 23/100\n",
      "3587/3587 [==============================] - 0s 92us/step - loss: 0.3292 - acc: 0.8793 - val_loss: 0.4780 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.83389\n",
      "Epoch 24/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.3268 - acc: 0.8804 - val_loss: 0.4711 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.83389\n",
      "Epoch 25/100\n",
      "3587/3587 [==============================] - 0s 95us/step - loss: 0.3230 - acc: 0.8840 - val_loss: 0.4693 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83389\n",
      "Epoch 26/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3209 - acc: 0.8801 - val_loss: 0.4711 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83389\n",
      "Epoch 27/100\n",
      "3587/3587 [==============================] - 0s 95us/step - loss: 0.3157 - acc: 0.8837 - val_loss: 0.4921 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83389\n",
      "Epoch 28/100\n",
      "3587/3587 [==============================] - 0s 101us/step - loss: 0.3142 - acc: 0.8835 - val_loss: 0.4690 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83389\n",
      "Epoch 29/100\n",
      "3587/3587 [==============================] - 0s 91us/step - loss: 0.3111 - acc: 0.8843 - val_loss: 0.4670 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83389\n",
      "Epoch 30/100\n",
      "3587/3587 [==============================] - 0s 97us/step - loss: 0.3076 - acc: 0.8871 - val_loss: 0.4727 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.83389\n",
      "Epoch 31/100\n",
      "3587/3587 [==============================] - 0s 94us/step - loss: 0.3053 - acc: 0.8876 - val_loss: 0.4714 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83389\n",
      "-----------------------------\n",
      "\n",
      "KSplit 0 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Train on 3587 samples, validate on 1794 samples\n",
      "Epoch 1/100\n",
      "3587/3587 [==============================] - 0s 100us/step - loss: 0.3773 - acc: 0.8628 - val_loss: 0.3143 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88796, saving model to models/USE_Embedding_CV_Model_fold1.001-0.8880.hdf5\n",
      "Epoch 2/100\n",
      "3587/3587 [==============================] - 0s 94us/step - loss: 0.3634 - acc: 0.8687 - val_loss: 0.3271 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88796\n",
      "Epoch 3/100\n",
      "3587/3587 [==============================] - 0s 101us/step - loss: 0.3519 - acc: 0.8718 - val_loss: 0.3307 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88796\n",
      "Epoch 4/100\n",
      "3587/3587 [==============================] - 0s 99us/step - loss: 0.3437 - acc: 0.8748 - val_loss: 0.3356 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88796\n",
      "Epoch 5/100\n",
      "3587/3587 [==============================] - 0s 94us/step - loss: 0.3407 - acc: 0.8751 - val_loss: 0.3396 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88796\n",
      "Epoch 6/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3354 - acc: 0.8773 - val_loss: 0.3451 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88796\n",
      "Epoch 7/100\n",
      "3587/3587 [==============================] - 0s 92us/step - loss: 0.3295 - acc: 0.8757 - val_loss: 0.3471 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.88796\n",
      "Epoch 8/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3255 - acc: 0.8784 - val_loss: 0.3525 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.88796\n",
      "Epoch 9/100\n",
      "3587/3587 [==============================] - 0s 96us/step - loss: 0.3210 - acc: 0.8821 - val_loss: 0.3574 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.88796\n",
      "Epoch 10/100\n",
      "3587/3587 [==============================] - 0s 103us/step - loss: 0.3153 - acc: 0.8815 - val_loss: 0.3577 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.88796\n",
      "Epoch 11/100\n",
      "3587/3587 [==============================] - 0s 93us/step - loss: 0.3135 - acc: 0.8863 - val_loss: 0.3572 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.88796\n",
      "-----------------------------\n",
      "\n",
      "KSplit 1 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Train on 3588 samples, validate on 1793 samples\n",
      "Epoch 1/100\n",
      "3588/3588 [==============================] - 0s 94us/step - loss: 0.3552 - acc: 0.8732 - val_loss: 0.2911 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89013, saving model to models/USE_Embedding_CV_Model_fold2.001-0.8901.hdf5\n",
      "Epoch 2/100\n",
      "3588/3588 [==============================] - 0s 99us/step - loss: 0.3428 - acc: 0.8757 - val_loss: 0.2859 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89013 to 0.89180, saving model to models/USE_Embedding_CV_Model_fold2.002-0.8918.hdf5\n",
      "Epoch 3/100\n",
      "3588/3588 [==============================] - 0s 100us/step - loss: 0.3354 - acc: 0.8776 - val_loss: 0.2827 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89180 to 0.89905, saving model to models/USE_Embedding_CV_Model_fold2.003-0.8991.hdf5\n",
      "Epoch 4/100\n",
      "3588/3588 [==============================] - 0s 95us/step - loss: 0.3279 - acc: 0.8790 - val_loss: 0.2861 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89905\n",
      "Epoch 5/100\n",
      "3588/3588 [==============================] - 0s 94us/step - loss: 0.3211 - acc: 0.8815 - val_loss: 0.2910 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89905\n",
      "Epoch 6/100\n",
      "3588/3588 [==============================] - 0s 92us/step - loss: 0.3176 - acc: 0.8829 - val_loss: 0.3011 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89905\n",
      "Epoch 7/100\n",
      "3588/3588 [==============================] - 0s 96us/step - loss: 0.3111 - acc: 0.8880 - val_loss: 0.2981 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89905\n",
      "Epoch 8/100\n",
      "3588/3588 [==============================] - 0s 99us/step - loss: 0.3078 - acc: 0.8863 - val_loss: 0.3016 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89905\n",
      "Epoch 9/100\n",
      "3588/3588 [==============================] - 0s 99us/step - loss: 0.3037 - acc: 0.8902 - val_loss: 0.3072 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89905\n",
      "Epoch 10/100\n",
      "3588/3588 [==============================] - 0s 98us/step - loss: 0.2982 - acc: 0.8910 - val_loss: 0.3118 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89905\n",
      "Epoch 11/100\n",
      "3588/3588 [==============================] - 0s 92us/step - loss: 0.2959 - acc: 0.8921 - val_loss: 0.3075 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89905\n",
      "Epoch 12/100\n",
      "3588/3588 [==============================] - 0s 99us/step - loss: 0.2921 - acc: 0.8949 - val_loss: 0.3147 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89905\n",
      "Epoch 13/100\n",
      "3588/3588 [==============================] - 0s 103us/step - loss: 0.2859 - acc: 0.8960 - val_loss: 0.3178 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.89905\n",
      "-----------------------------\n",
      "\n",
      "KSplit 2 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_CV_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn_cross_validated(question_embeddings_train, labels_train_categorical,\n",
    "                                                                                           question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1029 17:44:58.267604 140537078560576 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5381 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "5381/5381 [==============================] - 5s 876us/step - loss: 1.2230 - acc: 0.5711 - val_loss: 0.5187 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84800, saving model to models/USE_Embedding_Tuned_Model.001-0.8480.hdf5\n",
      "Epoch 2/100\n",
      "5381/5381 [==============================] - 1s 118us/step - loss: 0.6248 - acc: 0.7774 - val_loss: 0.3827 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84800 to 0.86800, saving model to models/USE_Embedding_Tuned_Model.002-0.8680.hdf5\n",
      "Epoch 3/100\n",
      "5381/5381 [==============================] - 1s 114us/step - loss: 0.5294 - acc: 0.8121 - val_loss: 0.3677 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86800 to 0.87000, saving model to models/USE_Embedding_Tuned_Model.003-0.8700.hdf5\n",
      "Epoch 4/100\n",
      "5381/5381 [==============================] - 1s 114us/step - loss: 0.4867 - acc: 0.8264 - val_loss: 0.3353 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87000 to 0.89000, saving model to models/USE_Embedding_Tuned_Model.004-0.8900.hdf5\n",
      "Epoch 5/100\n",
      "5381/5381 [==============================] - 1s 109us/step - loss: 0.4638 - acc: 0.8331 - val_loss: 0.3229 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89000\n",
      "Epoch 6/100\n",
      "5381/5381 [==============================] - 1s 113us/step - loss: 0.4480 - acc: 0.8348 - val_loss: 0.3083 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89000\n",
      "Epoch 7/100\n",
      "5381/5381 [==============================] - 1s 113us/step - loss: 0.4147 - acc: 0.8497 - val_loss: 0.3063 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89000\n",
      "Epoch 8/100\n",
      "5381/5381 [==============================] - 1s 115us/step - loss: 0.4063 - acc: 0.8560 - val_loss: 0.2885 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.89000 to 0.89400, saving model to models/USE_Embedding_Tuned_Model.008-0.8940.hdf5\n",
      "Epoch 9/100\n",
      "5381/5381 [==============================] - 1s 112us/step - loss: 0.3819 - acc: 0.8608 - val_loss: 0.3012 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89400\n",
      "Epoch 10/100\n",
      "5381/5381 [==============================] - 1s 111us/step - loss: 0.3781 - acc: 0.8584 - val_loss: 0.2725 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89400\n",
      "Epoch 11/100\n",
      "5381/5381 [==============================] - 1s 114us/step - loss: 0.3535 - acc: 0.8697 - val_loss: 0.2679 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.89400 to 0.90400, saving model to models/USE_Embedding_Tuned_Model.011-0.9040.hdf5\n",
      "Epoch 12/100\n",
      "5381/5381 [==============================] - 1s 108us/step - loss: 0.3499 - acc: 0.8746 - val_loss: 0.2747 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90400\n",
      "Epoch 13/100\n",
      "5381/5381 [==============================] - 1s 113us/step - loss: 0.3343 - acc: 0.8792 - val_loss: 0.2682 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.90400 to 0.90400, saving model to models/USE_Embedding_Tuned_Model.013-0.9040.hdf5\n",
      "Epoch 14/100\n",
      "5381/5381 [==============================] - 1s 115us/step - loss: 0.3269 - acc: 0.8777 - val_loss: 0.2892 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90400\n",
      "Epoch 15/100\n",
      "5381/5381 [==============================] - 1s 110us/step - loss: 0.3110 - acc: 0.8839 - val_loss: 0.2729 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90400\n",
      "Epoch 16/100\n",
      "5381/5381 [==============================] - 1s 110us/step - loss: 0.2937 - acc: 0.8930 - val_loss: 0.2649 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90400\n",
      "Epoch 17/100\n",
      "5381/5381 [==============================] - 1s 110us/step - loss: 0.2872 - acc: 0.8928 - val_loss: 0.2745 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90400\n",
      "Epoch 18/100\n",
      "5381/5381 [==============================] - 1s 113us/step - loss: 0.2828 - acc: 0.8924 - val_loss: 0.2841 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90400\n",
      "Epoch 19/100\n",
      "5381/5381 [==============================] - 1s 116us/step - loss: 0.2652 - acc: 0.9039 - val_loss: 0.2708 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90400\n",
      "Epoch 20/100\n",
      "5381/5381 [==============================] - 1s 112us/step - loss: 0.2624 - acc: 0.9050 - val_loss: 0.2875 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.90400 to 0.90800, saving model to models/USE_Embedding_Tuned_Model.020-0.9080.hdf5\n",
      "Epoch 21/100\n",
      "5381/5381 [==============================] - 1s 112us/step - loss: 0.2508 - acc: 0.9108 - val_loss: 0.2719 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.90800\n",
      "Epoch 22/100\n",
      "5381/5381 [==============================] - 1s 120us/step - loss: 0.2335 - acc: 0.9162 - val_loss: 0.2683 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.90800 to 0.91000, saving model to models/USE_Embedding_Tuned_Model.022-0.9100.hdf5\n",
      "Epoch 23/100\n",
      "5381/5381 [==============================] - 1s 112us/step - loss: 0.2295 - acc: 0.9143 - val_loss: 0.2687 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.91000 to 0.91800, saving model to models/USE_Embedding_Tuned_Model.023-0.9180.hdf5\n",
      "Epoch 24/100\n",
      "5381/5381 [==============================] - 1s 119us/step - loss: 0.2339 - acc: 0.9128 - val_loss: 0.2729 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.91800\n",
      "Epoch 25/100\n",
      "5381/5381 [==============================] - 1s 115us/step - loss: 0.2137 - acc: 0.9212 - val_loss: 0.2655 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.91800\n",
      "Epoch 26/100\n",
      "5381/5381 [==============================] - 1s 116us/step - loss: 0.2115 - acc: 0.9221 - val_loss: 0.2702 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.91800\n",
      "Epoch 27/100\n",
      "5381/5381 [==============================] - 1s 118us/step - loss: 0.2064 - acc: 0.9240 - val_loss: 0.2794 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.91800\n",
      "Epoch 28/100\n",
      "5381/5381 [==============================] - 1s 114us/step - loss: 0.2031 - acc: 0.9255 - val_loss: 0.2752 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.91800\n",
      "Epoch 29/100\n",
      "5381/5381 [==============================] - 1s 114us/step - loss: 0.1924 - acc: 0.9320 - val_loss: 0.2672 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.91800\n",
      "Epoch 30/100\n",
      "5381/5381 [==============================] - 1s 109us/step - loss: 0.1810 - acc: 0.9346 - val_loss: 0.2701 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.91800\n",
      "Epoch 31/100\n",
      "5381/5381 [==============================] - 1s 118us/step - loss: 0.1923 - acc: 0.9272 - val_loss: 0.2865 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.91800\n",
      "Epoch 32/100\n",
      "5381/5381 [==============================] - 1s 113us/step - loss: 0.1752 - acc: 0.9376 - val_loss: 0.2878 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.91800\n",
      "Epoch 33/100\n",
      "5381/5381 [==============================] - 1s 108us/step - loss: 0.1587 - acc: 0.9426 - val_loss: 0.2833 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.91800\n"
     ]
    }
   ],
   "source": [
    "# Train Tuned Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_tuned_classifier = QNAClassifier(\"USE_Embedding_Tuned_Model\")\n",
    "use_embedding_tuned_training_history = use_embedding_tuned_classifier.train_tuned_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(use_embedding_tuned_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the test classification metrics for the above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.88      0.94      0.91       138\n",
      "        ENTY       0.88      0.74      0.80        94\n",
      "         HUM       0.92      0.94      0.93        65\n",
      "         LOC       0.90      0.91      0.91        81\n",
      "         NUM       0.93      0.97      0.95       113\n",
      "\n",
      "    accuracy                           0.90       500\n",
      "   macro avg       0.92      0.88      0.90       500\n",
      "weighted avg       0.90      0.90      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: Please use the appropriate model path corresponding to your training step.\n",
    "print(generate_classification_report(model_path = 'models/USE_Embedding_Tuned_Model.013-0.9040.hdf5', \n",
    "                                     label_encoder = label_encoder,\n",
    "                                     test_features = question_embeddings_test,\n",
    "                                     test_labels = labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT: Bidirectional Encoder Representation from Transformers \n",
    "<u>Refrence Paper</u>: https://arxiv.org/abs/1810.04805<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n",
    "\n",
    "**BERT** is the current state of the art Language Model and is designed by pre-training deep bidirectional representations from unlabeled(Wikipedia)text by jointly conditioning on both left and right context in all layers.\n",
    "BERTs model architecture is a multi-layer/stacked set of bidirectional Transformers with the following 2 variants:\n",
    "**BERTBASE** (L=12, H=768, A=12, Total Parameters=110M) and **BERTLARGE** (L=24, H=1024, A=16, Total Parameters=340M).\n",
    "\n",
    "![dep_nobj-1](images/BERT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Data Prep for BERT Q&A classification</h3>\n",
    "\n",
    "Since BERT is a pre-trained Langauage Model, fine-tuning tasks using BERT is expected to have the same input format of data as that of BERT's training. In a nutshell, we'll have to apply the following transformations to our input text to conform to BERT's fine tuning input expectation.\n",
    "    \n",
    "- Lowercase our text (if we're using a BERT lowercase model)<br>\n",
    "- Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])<br>\n",
    "- Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])<br>\n",
    "- Map our words to indexes using a vocab file that BERT provides<br>\n",
    "- Add special \"CLS\" and \"SEP\" tokens for NextSentenceIdentication (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n",
    "- Append \"index\" and \"segment\" tokens to each input (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT Imports: BERT Classification\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fortunately, there are multiple libraries that'll trannsform our raw Question text to a format that BERT understands\n",
    "**bert.run_classifier.InputExample** is a data structure that will store the tranformed Quesstion text into BERT Input format. The below lambda section is only initializing these BERT Input format data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_train, labels_train))\n",
    "test_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download the pre-trained BERT base model and load up the BERT tokenizers to operate on our transformed Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 17:48:34.971814 140537078560576 saver.py:1505] Saver not created because there are no variables in the graph to restore\n",
      "W1029 17:48:35.381974 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"\n",
    "    Load the pre-trained BERT model and extract the vocab file and tokenizer from TF HUB\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BERT tokenizer object: bert.tokenization.FullTokenizer\n",
    "        See: https://github.com/google-research/bert/blob/master/tokenization.py\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time to run the pre-trained BERT tokenizer on our input Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1029 17:48:40.969225 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I1029 17:48:40.970137 140537078560576 run_classifier.py:774] Writing example 0 of 5381\n",
      "I1029 17:48:40.970887 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:40.971492 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:40.972039 140537078560576 run_classifier.py:464] tokens: [CLS] how did ser ##f ##dom develop in and then leave russia ? [SEP]\n",
      "I1029 17:48:40.972563 140537078560576 run_classifier.py:465] input_ids: 101 2129 2106 14262 2546 9527 4503 1999 1998 2059 2681 3607 1029 102 0 0 0 0 0 0\n",
      "I1029 17:48:40.973091 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "I1029 17:48:40.973600 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.974088 140537078560576 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1029 17:48:40.974827 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:40.975546 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:40.978339 140537078560576 run_classifier.py:464] tokens: [CLS] what films featured the character pope ##ye doyle ? [SEP]\n",
      "I1029 17:48:40.978857 140537078560576 run_classifier.py:465] input_ids: 101 2054 3152 2956 1996 2839 4831 6672 11294 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.979354 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.979855 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.980353 140537078560576 run_classifier.py:468] label: ENTY (id = 5)\n",
      "I1029 17:48:40.981074 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:40.981593 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:40.982092 140537078560576 run_classifier.py:464] tokens: [CLS] how can i find a list of celebrities ' real names ? [SEP]\n",
      "I1029 17:48:40.982594 140537078560576 run_classifier.py:465] input_ids: 101 2129 2064 1045 2424 1037 2862 1997 12330 1005 2613 3415 1029 102 0 0 0 0 0 0\n",
      "I1029 17:48:40.983104 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "I1029 17:48:40.983605 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.984100 140537078560576 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1029 17:48:40.984884 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:40.985402 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:40.986297 140537078560576 run_classifier.py:464] tokens: [CLS] what f ##ow ##l grabs the spotlight after the chinese year of the monkey ? [SEP]\n",
      "I1029 17:48:40.986819 140537078560576 run_classifier.py:465] input_ids: 101 2054 1042 5004 2140 13273 1996 17763 2044 1996 2822 2095 1997 1996 10608 1029 102 0 0 0\n",
      "I1029 17:48:40.987303 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "I1029 17:48:40.987798 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.988310 140537078560576 run_classifier.py:468] label: ENTY (id = 5)\n",
      "I1029 17:48:40.988970 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:40.989496 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:40.990034 140537078560576 run_classifier.py:464] tokens: [CLS] what is the full form of . com ? [SEP]\n",
      "I1029 17:48:40.990523 140537078560576 run_classifier.py:465] input_ids: 101 2054 2003 1996 2440 2433 1997 1012 4012 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.991028 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.991539 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:40.992036 140537078560576 run_classifier.py:468] label: ABBR (id = 3)\n",
      "I1029 17:48:42.041199 140537078560576 run_classifier.py:774] Writing example 0 of 500\n",
      "I1029 17:48:42.042090 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:42.042706 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:42.043329 140537078560576 run_classifier.py:464] tokens: [CLS] how far is it from denver to aspen ? [SEP]\n",
      "I1029 17:48:42.043840 140537078560576 run_classifier.py:465] input_ids: 101 2129 2521 2003 2009 2013 7573 2000 18567 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.044349 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.044975 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.045478 140537078560576 run_classifier.py:468] label: NUM (id = 2)\n",
      "I1029 17:48:42.046170 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:42.046697 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:42.047199 140537078560576 run_classifier.py:464] tokens: [CLS] what county is modest ##o , california in ? [SEP]\n",
      "I1029 17:48:42.047710 140537078560576 run_classifier.py:465] input_ids: 101 2054 2221 2003 10754 2080 1010 2662 1999 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.048211 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.048725 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.049225 140537078560576 run_classifier.py:468] label: LOC (id = 0)\n",
      "I1029 17:48:42.049841 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:42.050352 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:42.050854 140537078560576 run_classifier.py:464] tokens: [CLS] who was galileo ? [SEP]\n",
      "I1029 17:48:42.051362 140537078560576 run_classifier.py:465] input_ids: 101 2040 2001 21514 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.051862 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.052365 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.052857 140537078560576 run_classifier.py:468] label: HUM (id = 4)\n",
      "I1029 17:48:42.053457 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:42.054001 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:42.054494 140537078560576 run_classifier.py:464] tokens: [CLS] what is an atom ? [SEP]\n",
      "I1029 17:48:42.055016 140537078560576 run_classifier.py:465] input_ids: 101 2054 2003 2019 13787 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.055521 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.056020 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.056506 140537078560576 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1029 17:48:42.057145 140537078560576 run_classifier.py:461] *** Example ***\n",
      "I1029 17:48:42.057645 140537078560576 run_classifier.py:462] guid: None\n",
      "I1029 17:48:42.058133 140537078560576 run_classifier.py:464] tokens: [CLS] when did hawaii become a state ? [SEP]\n",
      "I1029 17:48:42.058635 140537078560576 run_classifier.py:465] input_ids: 101 2043 2106 7359 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.059119 140537078560576 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.059605 140537078560576 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1029 17:48:42.060091 140537078560576 run_classifier.py:468] label: NUM (id = 2)\n"
     ]
    }
   ],
   "source": [
    "# This is the max length of tokens in our Question text dataset\n",
    "# Exercise: Modify this MAX_SEQ_LENGTH value to see how it affects the training process\n",
    "MAX_SEQ_LENGTH = 20\n",
    "label_list = list(set(labels_train))\n",
    "\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Definition for BERT Q&A classification\n",
    "\n",
    "We'll use Tensorflow's Estimator API/Framework to train our fine-tuned BERT Q&A classification network. See https://www.tensorflow.org/guide/estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "    \"\"\"\n",
    "    Our Custom fine-tuning Q&A classifier definition using BERT output layers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    is_predicting: boolean\n",
    "        Boolean variable to indicate Training or Prediction mode.\n",
    "\n",
    "    input_ids: Numpy Array\n",
    "        BERT vocab token index for the input sample.\n",
    "\n",
    "    input_mask: Numpy Array\n",
    "        Flag to indicate if the input token is masked (1: Yes, 0:No).\n",
    "\n",
    "    segment_ids: Numpy Array\n",
    "        Flag to indicate which sentence the token belongs to. (0: 1st sentence, 1:2nd sentence).\n",
    "        \n",
    "    labels: Numpy Array\n",
    "        Classification label for the input.\n",
    "        \n",
    "    num_labels: integer\n",
    "        Total number of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    In Training Mode return (Training Loss, Evaluation Labels, Evaluation probs per sample) tuple\n",
    "    In Prediction Mode return (Evaluation Labels, Evaluation probs per sample) tuple\n",
    "\n",
    "    \"\"\"\n",
    "    bert_module = hub.Module( BERT_MODEL_HUB,trainable=True)\n",
    "    bert_inputs = dict( input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Tunable layer.\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],\n",
    "                                     initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimator driver logic for Training, Evaluation and Predict modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"\n",
    "    Estimator driver logic for Training, Evaluation and Predict modes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_labels : integer\n",
    "        Total number of labels\n",
    "        \n",
    "    learning_rate : float\n",
    "        Learning rate for underlying neural network\n",
    "        \n",
    "    num_train_steps: integer\n",
    "        Number of steps to train (Sample Size/(Batch Size*Number of Epochs))\n",
    "        \n",
    "    num_warmup_steps: float\n",
    "        Dynamic learning rate adjustment proportion\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model_fn closure: Python Object\n",
    "        Returns a closure of the driver logic\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        \"\"\"\n",
    "        Definition for Training, Evaluation and Predict modes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features: Dictionary\n",
    "            Training/Test features\n",
    "            \n",
    "        labels: Numpy Array\n",
    "            Train/Test labels\n",
    "            \n",
    "        mode: Numpy Array\n",
    "            Train/Eval/Predict\n",
    "            \n",
    "        params: Dictionary\n",
    "            Dict with training hyperparams\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        EstimatorSpec: tf.estimator.EstimatorSpec\n",
    "            https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            # Get BERT model definition\n",
    "            (loss, predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics.\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                \"\"\"\n",
    "                Function to calculate training/evaluation metrics\n",
    "                \"\"\"\n",
    "                \n",
    "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "                \n",
    "                return {\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Modify the below values and observe the change in the training process\n",
    "# Compute train and warmup steps from batch size\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 10\n",
    "SAVE_SUMMARY_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir='models',\n",
    "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "                                    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 17:50:35.052040 140537078560576 estimator.py:209] Using config: {'_model_dir': 'models', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcdfc04beb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(num_labels=len(label_list), learning_rate=LEARNING_RATE,\n",
    "                            num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder( features=train_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                      is_training=True, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1029 17:50:59.326838 140537078560576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 17:50:59.850593 140537078560576 estimator.py:1145] Calling model_fn.\n",
      "I1029 17:51:02.894720 140537078560576 saver.py:1505] Saver not created because there are no variables in the graph to restore\n",
      "W1029 17:51:03.091677 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W1029 17:51:03.098777 140537078560576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "W1029 17:51:03.103721 140537078560576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "I1029 17:51:12.256539 140537078560576 estimator.py:1147] Done calling model_fn.\n",
      "I1029 17:51:12.259187 140537078560576 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I1029 17:51:15.714554 140537078560576 monitored_session.py:240] Graph was finalized.\n",
      "I1029 17:51:21.044860 140537078560576 session_manager.py:500] Running local_init_op.\n",
      "I1029 17:51:21.283152 140537078560576 session_manager.py:502] Done running local_init_op.\n",
      "I1029 17:51:29.960479 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 0 into models/model.ckpt.\n",
      "I1029 17:51:55.253385 140537078560576 basic_session_run_hooks.py:262] loss = 1.7695894, step = 1\n",
      "I1029 17:52:49.990939 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 10 into models/model.ckpt.\n",
      "I1029 17:53:07.689026 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 20 into models/model.ckpt.\n",
      "I1029 17:53:25.470800 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 30 into models/model.ckpt.\n",
      "I1029 17:53:43.205932 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 40 into models/model.ckpt.\n",
      "I1029 17:54:00.861625 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 50 into models/model.ckpt.\n",
      "W1029 17:54:02.080680 140537078560576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "I1029 17:54:18.809033 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 60 into models/model.ckpt.\n",
      "I1029 17:54:36.948458 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 70 into models/model.ckpt.\n",
      "I1029 17:54:54.935890 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 80 into models/model.ckpt.\n",
      "I1029 17:55:13.329331 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 90 into models/model.ckpt.\n",
      "I1029 17:55:31.251816 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 100 into models/model.ckpt.\n",
      "W1029 17:55:33.957652 140537078560576 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 99 vs previous value: 99. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1029 17:55:56.091253 140537078560576 basic_session_run_hooks.py:692] global_step/sec: 0.415217\n",
      "I1029 17:55:56.092240 140537078560576 basic_session_run_hooks.py:260] loss = 0.25325954, step = 101 (240.839 sec)\n",
      "W1029 17:55:57.615147 140537078560576 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 101 vs previous value: 101. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1029 17:56:09.849681 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 110 into models/model.ckpt.\n",
      "I1029 17:56:28.246624 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 120 into models/model.ckpt.\n",
      "I1029 17:56:46.121845 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 130 into models/model.ckpt.\n",
      "I1029 17:57:04.122026 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 140 into models/model.ckpt.\n",
      "I1029 17:57:22.135769 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 150 into models/model.ckpt.\n",
      "I1029 17:57:40.275624 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 160 into models/model.ckpt.\n",
      "I1029 17:57:58.227079 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 170 into models/model.ckpt.\n",
      "I1029 17:58:16.206423 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 180 into models/model.ckpt.\n",
      "I1029 17:58:34.205291 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 190 into models/model.ckpt.\n",
      "I1029 17:58:53.011301 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 200 into models/model.ckpt.\n",
      "I1029 17:58:57.188634 140537078560576 basic_session_run_hooks.py:692] global_step/sec: 0.552189\n",
      "I1029 17:58:57.189734 140537078560576 basic_session_run_hooks.py:260] loss = 0.09069444, step = 201 (181.097 sec)\n",
      "I1029 17:59:11.061026 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 210 into models/model.ckpt.\n",
      "I1029 17:59:28.929887 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 220 into models/model.ckpt.\n",
      "I1029 17:59:46.970209 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 230 into models/model.ckpt.\n",
      "I1029 18:00:04.841270 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 240 into models/model.ckpt.\n",
      "I1029 18:00:23.159440 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 250 into models/model.ckpt.\n",
      "I1029 18:00:41.175661 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 260 into models/model.ckpt.\n",
      "I1029 18:00:59.085664 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 270 into models/model.ckpt.\n",
      "I1029 18:01:17.073640 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 280 into models/model.ckpt.\n",
      "I1029 18:01:35.032827 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 290 into models/model.ckpt.\n",
      "I1029 18:01:53.835668 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 300 into models/model.ckpt.\n",
      "I1029 18:01:57.931342 140537078560576 basic_session_run_hooks.py:692] global_step/sec: 0.553273\n",
      "I1029 18:01:57.932311 140537078560576 basic_session_run_hooks.py:260] loss = 0.055690598, step = 301 (180.743 sec)\n",
      "I1029 18:02:11.788251 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 310 into models/model.ckpt.\n",
      "I1029 18:02:29.696830 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 320 into models/model.ckpt.\n",
      "I1029 18:02:47.784926 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 330 into models/model.ckpt.\n",
      "I1029 18:03:05.739193 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 340 into models/model.ckpt.\n",
      "I1029 18:03:23.633987 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 350 into models/model.ckpt.\n",
      "I1029 18:03:41.551995 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 360 into models/model.ckpt.\n",
      "I1029 18:03:59.482053 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 370 into models/model.ckpt.\n",
      "I1029 18:04:17.510540 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 380 into models/model.ckpt.\n",
      "I1029 18:04:35.408463 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 390 into models/model.ckpt.\n",
      "I1029 18:04:54.279850 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 400 into models/model.ckpt.\n",
      "I1029 18:04:58.642035 140537078560576 basic_session_run_hooks.py:692] global_step/sec: 0.553371\n",
      "I1029 18:04:58.643011 140537078560576 basic_session_run_hooks.py:260] loss = 0.0064912857, step = 401 (180.711 sec)\n",
      "I1029 18:05:12.476740 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 410 into models/model.ckpt.\n",
      "I1029 18:05:30.678301 140537078560576 basic_session_run_hooks.py:606] Saving checkpoints for 420 into models/model.ckpt.\n",
      "I1029 18:05:33.997155 140537078560576 estimator.py:368] Loss for final step: 0.009074567.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Training\n"
     ]
    }
   ],
   "source": [
    "print('Start Training')\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"End Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(features=test_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                is_training=False, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 18:05:48.487009 140537078560576 estimator.py:1145] Calling model_fn.\n",
      "I1029 18:05:50.935012 140537078560576 saver.py:1505] Saver not created because there are no variables in the graph to restore\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "I1029 18:06:00.873317 140537078560576 estimator.py:1147] Done calling model_fn.\n",
      "I1029 18:06:00.895522 140537078560576 evaluation.py:255] Starting evaluation at 2019-10-29T18:06:00Z\n",
      "I1029 18:06:02.338138 140537078560576 monitored_session.py:240] Graph was finalized.\n",
      "W1029 18:06:02.339644 140537078560576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I1029 18:06:02.341626 140537078560576 saver.py:1286] Restoring parameters from models/model.ckpt-420\n",
      "I1029 18:06:05.545041 140537078560576 session_manager.py:500] Running local_init_op.\n",
      "I1029 18:06:05.790141 140537078560576 session_manager.py:502] Done running local_init_op.\n",
      "I1029 18:06:13.709095 140537078560576 evaluation.py:275] Finished evaluation at 2019-10-29-18:06:13\n",
      "I1029 18:06:13.710212 140537078560576 estimator.py:2039] Saving dict for global step 420: false_negatives = 3.0, false_positives = 2.0, global_step = 420, loss = 0.14986831, precision = 0.9952153, recall = 0.9928401, true_negatives = 79.0, true_positives = 416.0\n",
      "I1029 18:06:16.383755 140537078560576 estimator.py:2099] Saving 'checkpoint_path' summary for global step 420: models/model.ckpt-420\n"
     ]
    }
   ],
   "source": [
    "metrics = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "metrics[\"accuracy\"] = (metrics[\"true_positives\"] + metrics[\"true_negatives\"])/(metrics[\"true_positives\"] + metrics[\"true_negatives\"]+metrics[\"false_positives\"] + metrics[\"false_negatives\"])\n",
    "metrics[\"f1_score\"] = (2*metrics[\"precision\"]*metrics[\"recall\"])/(metrics[\"precision\"]+metrics[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false_negatives': 3.0,\n",
       " 'false_positives': 2.0,\n",
       " 'loss': 0.14986831,\n",
       " 'precision': 0.9952153,\n",
       " 'recall': 0.9928401,\n",
       " 'true_negatives': 79.0,\n",
       " 'true_positives': 416.0,\n",
       " 'global_step': 420,\n",
       " 'accuracy': 0.99,\n",
       " 'f1_score': 0.9940262553478724}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the training metrics on the Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Plot the training metrics using Tensorboard\n",
    "# import tensorboard\n",
    "# !tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "As seen from the chart below, although BERT outperforms most previous state of the art techniques, it does not justify using such a model as a standalone solution to solve business problems. An ensembled or hybrid approach would be much more desirable to achieve business needs. Figuring out the set of metrics that are most applicable to measure the success of the chosen modeling techniques should ulimately drive the modeling decisions. \n",
    "\n",
    "Since BERT was trained on a general Wikipedia corpus, it was able to perform extremely well on the TREC question classification datasets. Real-world business problems are rarely generic in nature and the datasets are highly domain specific which require us to retrain a language model like BERT(for a couple of days with lots of GPU/TPU power) which can very well produce un-favorable results. Hence Deep Learning should never be the first approach to solve a business problem rather a systematic investigation of the data and step-by-step exploration of algorithms should guide your problem solving process. \n",
    "\n",
    "![dep_nobj-1](images/Conclusion.png)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Universal Sentence Encoder: https://arxiv.org/abs/1803.11175\n",
    "- Tensorflow Estimator: https://www.tensorflow.org/guide/estimator\n",
    "- BERT: https://arxiv.org/abs/1810.04805"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
