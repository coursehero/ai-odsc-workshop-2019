{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop Description\n",
    "Understanding the questions posed by instructors and students alike plays an important role in the development of educational technology applications. In this intermediate level workshop, you will learn to apply NLP to one piece of this real-world problem by building a model to predict the type of answer (e.g. entity, description, number, etc.) a question elicits. Specifically, you will learn to:\n",
    "1. Perform preprocessing, normalization, and exploratory analysis on a question dataset,\n",
    "2. Identify salient linguistic features of natural language questions, and\n",
    "3. Experiment with different feature sets and models to predict the answer type.\n",
    "4. Use powerful pretrained language models to create dense sentence representations and apply deep learning models to text classification.\n",
    "\n",
    "The concepts will be taught using popular NLP and ML packages like SpaCy, Scikit Learn, and Tensorflow.\n",
    "\n",
    "This workshop assumes familiarity with Jupyter notebooks and the basics of scientific packages like numPy and sciPy. We also assume some basic knowledge of machine learning and deep learning techniques like CNNs, LSTMs, etc. Reference materials will be provided to gain a better understanding of these techniques for interested attendees.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Representation Learning to classify TREC question-classification text\n",
    "\n",
    "**Overview:** \n",
    "In this session we'll try to solve the TREC question-classification problem by using a few popular Deep Learning Algorithms.\n",
    "Concretely, we will use pre-trained Language Models to generate **representations(Embeddings)** for our input data and then classify these representations using a shallow neural network.\n",
    "We will examine the network architectures of **Universal Sentence Encoder(USE)** and **Bidirectional Encoder Representation from Transformers(BERT)** and touch upon the pros and cons of these architectures in classifying TREC question-classification data.\n",
    "\n",
    "### What you'll learn:\n",
    "- How to use **Keras** for Text classification\n",
    "- How to generate representations using pre-trained **Universal Sentence Encoder: USE**\n",
    "- How to tune and evaluate Deep Learning models \n",
    "- How to use **Tensorflow** for Text classification\n",
    "- How to use pre-trained Language Model **Bidirectional Encoder Representation from Transformers: BERT** for Text classification\n",
    "\n",
    "**Note:** We will be using the same dataset as the previous 2 sessions. Notebook links to the previous session are available **INSERT LINK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Represenations:\n",
    "![dep_nobj-1](images/Word2Vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Representation\n",
    "![dep_nobj-1](images/SentenceEmbedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "The following two utility functions provide functionality that can be used across different models to inspect training metrics and performance. These will be used at a later point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matplotlib Plotting Import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Function to plot training accuracy/loss, validation accuracy/loss.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history: \n",
    "        Keras training history object. See: https://keras.io/callbacks/#history\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Keras Imports: USE Embedding Classification\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#Sklearn Utility Imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def generate_classification_report(model_path, label_encoder, test_features, test_labels, class_names=None):\n",
    "    \"\"\"\n",
    "    Function to generate SKLearn based multi class classification report\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path: Path to trained model.\n",
    "    label_encoder: Encoder used during label transformation\n",
    "    test_features: Features for test.\n",
    "    test_labels: Ground truth labels\n",
    "    class_names: Class names for the true and pred integer values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: sklearn.metrics.classification_report\n",
    "        MultiClass Classification Report.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pre-trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Predict labels for test features\n",
    "    preds = model.predict(test_features)\n",
    "    \n",
    "    # Since the model is trained to return a set of probabilities across the label set, \n",
    "    # we'll have to find the index of label set with the highest probability score.\n",
    "    preds_index = np.argmax(preds, axis=1)\n",
    "    \n",
    "    # Converting the predicted index into the original TREC based label\n",
    "    preds_labels = label_encoder.inverse_transform(preds_index)\n",
    "    \n",
    "    return classification_report(test_labels, preds_labels, target_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "First let's download the train and test data from Xin Li, Dan Roth, Learning Question Classifiers. COLING'02, Aug., 2002.\n",
    "    <https://cogcomp.seas.upenn.edu/Data/QA/QC/\">https://cogcomp.seas.upenn.edu/Data/QA/QC/>\n",
    "    \n",
    "We will store these data in Pandas DataFrames (and write them as .csv files) containing the following columns:\n",
    "- *question*: The question text\n",
    "- *processed_question*: The question as a SpaCy Doc object\n",
    "- *coarse_label*: The coarse-grained label (6 classes)\n",
    "- *label*: The fine-grained label\n",
    "\n",
    "Recall that in Module 1, we found that some questions were duplicated. Let's remove those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'data' already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from download_data import main as download_trec_data\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "download_trec_data()\n",
    "\n",
    "path_to_train = os.path.join(\"data\", \"train.csv\")\n",
    "path_to_test = os.path.join(\"data\", \"test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(\"data\", \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(\"data\", \"test.csv\"))\n",
    "\n",
    "#\n",
    "# Dedupe from python module.\n",
    "#\n",
    "train_df = train_df.drop_duplicates(\"question\")\n",
    "test_df = test_df.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder\n",
    "<u>Reference Paper</u>: https://arxiv.org/abs/1803.11175<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html<br><br>\n",
    "**Universal Sentence Encoder (USE)** is a versatile sentence embedding model that convert sentences into vector representations. These vectors capture rich semantic information that can be used to train classifiers for a broad range of downstream tasks.\n",
    "\n",
    "![dep_nobj-1](images/USE.png)\n",
    "\n",
    "Note: USE can work on small multi sentence paragraphs.\n",
    "\n",
    "\n",
    "### High level steps for classifying text using pre-trained USE model: \n",
    "- Download Pre-trained USE Model from Tensorflow HUB<br>\n",
    "- Extract USE Repesentations for both train and test sets<br>\n",
    "- Define a the classification network architecture<br>\n",
    "- Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for USE Q&A classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process_text(input_text):\n",
    "    \"\"\"\n",
    "    Function to normalize text by applying NLP tranformations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text: String \n",
    "        Question text from the input sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String\n",
    "        pre-processed version of input string\n",
    "    \"\"\"\n",
    "    #Exercise: build multiple models based on diferrent pre-processing techniques.\n",
    "    #Un-Comment the below line to see if the model performance improves by introducing additional \n",
    "    #input_text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', input_text)\n",
    "    return input_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the raw question text and labels from the training and test dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_df['question'].to_list()\n",
    "features_test  = test_df['question'].to_list()\n",
    "labels_train   = train_df['coarse_label'].to_list()\n",
    "labels_test    = test_df['coarse_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-Process the text used for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process the text used for training and test\n",
    "features_train_processed = list(map(lambda x:pre_process_text(x), features_train))\n",
    "features_test_processed = list(map(lambda x:pre_process_text(x), features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The labels for the training and test set are in a string format (eg: ABBR, DESC etc). These labels need to be converted into a numerical set using [Scikit Learn's Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process labels for training\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels_train_tranformed = label_encoder.fit_transform(labels_train)\n",
    "labels_train_categorical = to_categorical(np.asarray(labels_train_tranformed))\n",
    "# Note: We do not have to \"fit\" the label encoder for the test set since they already have been fit on the trainset\n",
    "labels_test_transformed = label_encoder.transform(labels_test)\n",
    "labels_test_categorical = to_categorical(np.asarray(labels_test_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and load the pre-trained Universal Sentence Encoder from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "pre_trained_use_embed_model = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate sentence/phrase representations of the training and test text data using the above downloaded USE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_features_train = []\n",
    "embeddings_features_test = []\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings_features_train.append(session.run(pre_trained_use_embed_model(features_train_processed)))\n",
    "    embeddings_features_test.append(session.run(pre_trained_use_embed_model(features_test_processed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train = embeddings_features_train[0]\n",
    "question_embeddings_test = embeddings_features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition for USE Q&A classification\n",
    "\n",
    "We will use the [Keras Functional API Guide](https://keras.io/getting-started/functional-api-guide/#first-example-a-densely-connected-network) to build and train the USE Q&A classifier network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNAClassifier():\n",
    "    \"\"\"\n",
    "    Q&A classifier class using Keras framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name):\n",
    "        \"\"\"\n",
    "        Init function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_name: String\n",
    "            Name of the experiment. This will be used to name the model checkpoints.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #Exercise: Modify the below hyper parameters to create variations of the USE Q&A classifier model.\n",
    "        self.patience = 10\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.experiment_name = experiment_name\n",
    "        self.output_dir = 'models'\n",
    "        self.class_count = 6\n",
    "        self.model = None\n",
    "        \n",
    "        # Creating an output directory for the generated models.\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    \n",
    "    def train_vanilla_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        Simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(256, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        # Start Training\n",
    "        training_history = self.model.fit(embeddings_train, labels_train, \n",
    "                                          validation_data = (embeddings_test, labels_test),\n",
    "                                          epochs= self.epochs,\n",
    "                                          batch_size=self.batch_size,\n",
    "                                          callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history\n",
    "    \n",
    "    def train_vanilla_nn_cross_validated(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        K-Fold Cross validated simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        list of training history objects\n",
    "            Keras training history object. See: https://keras.io/callbacks/#history\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(64, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        \n",
    "        training_histories = []\n",
    "        counter = 0\n",
    "        \n",
    "        #Exercise: Experiment with different number of splits.\n",
    "        kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "        for train_index, test_index in kf.split(embeddings_train):\n",
    "            \n",
    "            X_train, X_test = embeddings_train[train_index], embeddings_train[test_index]\n",
    "            y_train, y_test = labels_train[train_index], labels_train[test_index]\n",
    "            \n",
    "            model_filename = self.output_dir + \"/\" + self.experiment_name + \"_fold{}\".format(counter)\n",
    "            checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                         monitor='val_acc', verbose=1,\n",
    "                                         save_best_only=True, mode='auto')\n",
    "        \n",
    "            # Start Training\n",
    "            training_history = self.model.fit(X_train, y_train, \n",
    "                                              validation_data = (X_test, y_test),\n",
    "                                              epochs= self.epochs,\n",
    "                                              batch_size=self.batch_size,\n",
    "                                              #Exercise: Add Tensorboard here\n",
    "                                              callbacks=[checkpoint, early_stopping])\n",
    "            \n",
    "            print(\"-----------------------------\\n\")\n",
    "            print(\"KSplit {} training complete\\n\".format(counter))\n",
    "            print(\"-----------------------------\\n\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            training_histories.append(training_history)\n",
    "        \n",
    "        return training_histories\n",
    "    \n",
    "    def train_tuned_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \n",
    "        \"\"\"\n",
    "        Tuned Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(128, activation='relu')(embedding_inputs)\n",
    "        # Added dropouts for regularization\n",
    "        # Exercise: Change the value of dropouts.\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        \n",
    "        # Start Training\n",
    "        training_history = model.fit(embeddings_train, labels_train, \n",
    "                                     validation_data = (embeddings_test, labels_test),\n",
    "                                     epochs= self.epochs,\n",
    "                                     batch_size=self.batch_size,\n",
    "                                     #Exercise: Add Tensorboard here\n",
    "                                     callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(use_embedding_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_CV_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn_cross_validated(question_embeddings_train, labels_train_categorical,\n",
    "                                                                                           question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Tuned Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_tuned_classifier = QNAClassifier(\"USE_Embedding_Tuned_Model\")\n",
    "use_embedding_tuned_training_history = use_embedding_tuned_classifier.train_tuned_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(use_embedding_tuned_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the test classification metrics for the above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Please use the appropriate model path corresponding to your training step.\n",
    "print(generate_classification_report(model_path = 'models/USE_Embedding_Tuned_Model.011-0.9140.hdf5', \n",
    "                                     label_encoder = label_encoder,\n",
    "                                     test_features = question_embeddings_test,\n",
    "                                     test_labels = labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT: Bidirectional Encoder Representation from Transformers \n",
    "<u>Refrence Paper</u>: https://arxiv.org/abs/1810.04805<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n",
    "\n",
    "**BERT** is the current state of the art Language Model and is designed by pre-training deep bidirectional representations from unlabeled(Wikipedia)text by jointly conditioning on both left and right context in all layers.\n",
    "BERT’s model architecture is a multi-layer/stacked set of bidirectional Transformers with the following 2 variants:\n",
    "**BERTBASE** (L=12, H=768, A=12, Total Parameters=110M) and **BERTLARGE** (L=24, H=1024, A=16, Total Parameters=340M).\n",
    "\n",
    "![dep_nobj-1](images/BERT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Data Prep for BERT Q&A classification</h3>\n",
    "\n",
    "Since BERT is a pre-trained Langauage Model, fine-tuning tasks using BERT is expected to have the same input format of data as that of BERT's training. In a nutshell, we'll have to apply the following transformations to our input text to conform to BERT's fine tuning input expectation.\n",
    "    \n",
    "- Lowercase our text (if we're using a BERT lowercase model)<br>\n",
    "- Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])<br>\n",
    "- Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])<br>\n",
    "- Map our words to indexes using a vocab file that BERT provides<br>\n",
    "- Add special \"CLS\" and \"SEP\" tokens for NextSentenceIdentication (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n",
    "- Append \"index\" and \"segment\" tokens to each input (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT Imports: BERT Classification\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fortunately, there are multiple libraries that'll trannsform our raw Question text to a format that BERT understands\n",
    "**bert.run_classifier.InputExample** is a data structure that will store the tranformed Quesstion text into BERT Input format. The below lambda section is only initializing these BERT Input format data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_train, labels_train))\n",
    "test_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download the pre-trained BERT base model and load up the BERT tokenizers to operate on our transformed Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"\n",
    "    Load the pre-trained BERT model and extract the vocab file and tokenizer from TF HUB\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BERT tokenizer object: bert.tokenization.FullTokenizer\n",
    "        See: https://github.com/google-research/bert/blob/master/tokenization.py\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time to run the pre-trained BERT tokenizer on our input Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the max length of tokens in our Question text dataset\n",
    "# Exercise: Modify this MAX_SEQ_LENGTH value to see how it affects the training process\n",
    "MAX_SEQ_LENGTH = 20\n",
    "label_list = list(set(labels_train))\n",
    "\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Definition for BERT Q&A classification\n",
    "\n",
    "We'll use Tensorflow's Estimator API/Framework to train our fine-tuned BERT Q&A classification network. See https://www.tensorflow.org/guide/estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "    \"\"\"\n",
    "    Our Custom fine-tuning Q&A classifier definition using BERT output layers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    is_predicting: boolean\n",
    "        Boolean variable to indicate Training or Prediction mode.\n",
    "\n",
    "    input_ids: Numpy Array\n",
    "        BERT vocab token index for the input sample.\n",
    "\n",
    "    input_mask: Numpy Array\n",
    "        Flag to indicate if the input token is masked (1: Yes, 0:No).\n",
    "\n",
    "    segment_ids: Numpy Array\n",
    "        Flag to indicate which sentence the token belongs to. (0: 1st sentence, 1:2nd sentence).\n",
    "        \n",
    "    labels: Numpy Array\n",
    "        Classification label for the input.\n",
    "        \n",
    "    num_labels: integer\n",
    "        Total number of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    In Training Mode return (Training Loss, Evaluation Labels, Evaluation probs per sample) tuple\n",
    "    In Prediction Mode return (Evaluation Labels, Evaluation probs per sample) tuple\n",
    "\n",
    "    \"\"\"\n",
    "    bert_module = hub.Module( BERT_MODEL_HUB,trainable=True)\n",
    "    bert_inputs = dict( input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Tunable layer.\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],\n",
    "                                     initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimator driver logic for Training, Evaluation and Predict modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"\n",
    "    Estimator driver logic for Training, Evaluation and Predict modes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_labels : integer\n",
    "        Total number of labels\n",
    "        \n",
    "    learning_rate : float\n",
    "        Learning rate for underlying neural network\n",
    "        \n",
    "    num_train_steps: integer\n",
    "        Number of steps to train (Sample Size/(Batch Size*Number of Epochs))\n",
    "        \n",
    "    num_warmup_steps: float\n",
    "        Dynamic learning rate adjustment proportion\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model_fn closure: Python Object\n",
    "        Returns a closure of the driver logic\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        \"\"\"\n",
    "        Definition for Training, Evaluation and Predict modes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features: Dictionary\n",
    "            Training/Test features\n",
    "            \n",
    "        labels: Numpy Array\n",
    "            Train/Test labels\n",
    "            \n",
    "        mode: Numpy Array\n",
    "            Train/Eval/Predict\n",
    "            \n",
    "        params: Dictionary\n",
    "            Dict with training hyperparams\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        EstimatorSpec: tf.estimator.EstimatorSpec\n",
    "            https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            # Get BERT model definition\n",
    "            (loss, predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics.\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                \"\"\"\n",
    "                Function to calculate training/evaluation metrics\n",
    "                \"\"\"\n",
    "                \n",
    "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "                \n",
    "                return {\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Modify the below values and observe the change in the training process\n",
    "# Compute train and warmup steps from batch size\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 10\n",
    "SAVE_SUMMARY_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir='models',\n",
    "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "                                    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(num_labels=len(label_list), learning_rate=LEARNING_RATE,\n",
    "                            num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder( features=train_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                      is_training=True, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Start Training')\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"End Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the training metrics on the Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "!tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(features=test_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                is_training=False, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "metrics[\"accuracy\"] = (metrics[\"true_positives\"] + metrics[\"true_negatives\"])/(metrics[\"true_positives\"] + metrics[\"true_negatives\"]+metrics[\"false_positives\"] + metrics[\"false_negatives\"])\n",
    "metrics[\"f1_score\"] = (2*metrics[\"precision\"]*metrics[\"recall\"])/(metrics[\"precision\"]+metrics[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "As seen from the chart below, although BERT outperforms most previous state of the art techniques, it does not justify using such a model as a standalone solution to solve business problems. An ensembled or hybrid approach would be much more desirable to achieve business needs. Figuring out the set of metrics that are most applicable to measure the success of the chosen modeling techniques should ulimately drive the modeling decisions. \n",
    "\n",
    "Since BERT was trained on a general Wikipedia corpus, it was able to perform extremely well on the TREC question classification datasets. Real-world business problems are rarely generic in nature and the datasets are highly domain specific which require us to retrain a language model like BERT(for a couple of days with lots of GPU/TPU power) which can very well produce un-favorable results. Hence Deep Learning should never be the first approach to solve a business problem rather a systematic investigation of the data and step-by-step exploration of algorithms should guide your problem solving process. \n",
    "\n",
    "![dep_nobj-1](images/Conclusion.png)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Universal Sentence Encoder: https://arxiv.org/abs/1803.11175\n",
    "- Tensorflow Estimator: https://www.tensorflow.org/guide/estimator\n",
    "- BERT: https://arxiv.org/abs/1810.04805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
