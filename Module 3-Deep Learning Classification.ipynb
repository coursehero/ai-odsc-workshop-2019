{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop Description\n",
    "Understanding the questions posed by instructors and students alike plays an important role in the development of educational technology applications. In this intermediate level workshop, you will learn to apply NLP to one piece of this real-world problem by building a model to predict the type of answer (e.g. entity, description, number, etc.) a question elicits. Specifically, you will learn to:\n",
    "1. Perform preprocessing, normalization, and exploratory analysis on a question dataset,\n",
    "2. Identify salient linguistic features of natural language questions, and\n",
    "3. Experiment with different feature sets and models to predict the answer type.\n",
    "4. Use powerful pretrained language models to create dense sentence representations and apply deep learning models to text classification.\n",
    "\n",
    "The concepts will be taught using popular NLP and ML packages like SpaCy, Scikit Learn, and Tensorflow.\n",
    "\n",
    "This workshop assumes familiarity with Jupyter notebooks and the basics of scientific packages like numPy and sciPy. We also assume some basic knowledge of machine learning and deep learning techniques like CNNs, LSTMs, etc. Reference materials will be provided to gain a better understanding of these techniques for interested attendees.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Representation Learning to classify TREC question-classification text\n",
    "\n",
    "**Overview:** \n",
    "In this session we'll try to solve the TREC question-classification problem by using a few popular Deep Learning Algorithms.\n",
    "Concretely, we will use pre-trained Language Models to generate **representations(Embeddings)** for our input data and then classify these representations using a shallow neural network.\n",
    "We will examine the network architectures of **Universal Sentence Encoder(USE)** and **Bidirectional Encoder Representation from Transformers(BERT)** and touch upon the pros and cons of these architectures in classifying TREC question-classification data.\n",
    "\n",
    "### What you'll learn:\n",
    "- How to use **Keras** for Text classification\n",
    "- How to generate representations using pre-trained **Universal Sentence Encoder: USE**\n",
    "- How to tune and evaluate Deep Learning models \n",
    "- How to use **Tensorflow** for Text classification\n",
    "- How to use pre-trained Language Model **Bidirectional Encoder Representation from Transformers: BERT** for Text classification\n",
    "\n",
    "**Note:** We will be using the same dataset as the previous 2 sessions. Notebook links to the previous session are available **INSERT LINK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Represenations:\n",
    "![dep_nobj-1](images/Word2Vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "The following two utility functions provide functionality that can be used across different models to inspect training metrics and performance. These will be used at a later point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matplotlib Plotting Import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Function to plot training accuracy/loss, validation accuracy/loss.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history: \n",
    "        Keras training history object. See: https://keras.io/callbacks/#history\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Keras Imports: USE Embedding Classification\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#Sklearn Utility Imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def generate_classification_report(model_path, label_encoder, test_features, test_labels, class_names=None):\n",
    "    \"\"\"\n",
    "    Function to generate SKLearn based multi class classification report\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path: Path to trained model.\n",
    "    label_encoder: Encoder used during label transformation\n",
    "    test_features: Features for test.\n",
    "    test_labels: Ground truth labels\n",
    "    class_names: Class names for the true and pred integer values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: sklearn.metrics.classification_report\n",
    "        MultiClass Classification Report.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pre-trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Predict labels for test features\n",
    "    preds = model.predict(test_features)\n",
    "    \n",
    "    # Since the model is trained to return a set of probabilities across the label set, \n",
    "    # we'll have to find the index of label set with the highest probability score.\n",
    "    preds_index = np.argmax(preds, axis=1)\n",
    "    \n",
    "    # Converting the predicted index into the original TREC based label\n",
    "    preds_labels = label_encoder.inverse_transform(preds_index)\n",
    "    \n",
    "    return classification_report(test_labels, preds_labels, target_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "First let's download the train and test data from Xin Li, Dan Roth, Learning Question Classifiers. COLING'02, Aug., 2002.\n",
    "    <https://cogcomp.seas.upenn.edu/Data/QA/QC/\">https://cogcomp.seas.upenn.edu/Data/QA/QC/>\n",
    "    \n",
    "We will store these data in Pandas DataFrames (and write them as .csv files) containing the following columns:\n",
    "- *question*: The question text\n",
    "- *processed_question*: The question as a SpaCy Doc object\n",
    "- *coarse_label*: The coarse-grained label (6 classes)\n",
    "- *label*: The fine-grained label\n",
    "\n",
    "Recall that in Module 1, we found that some questions were duplicated. Let's remove those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from download_data import main as download_trec_data\n",
    "\n",
    "path_to_train = os.path.join(\"data\", \"train.csv\")\n",
    "path_to_test = os.path.join(\"data\", \"test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(\"data\", \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(\"data\", \"test.csv\"))\n",
    "\n",
    "#\n",
    "# Dedupe from python module.\n",
    "#\n",
    "train_df = train_df.drop_duplicates(\"question\")\n",
    "test_df = test_df.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder\n",
    "<u>Reference Paper</u>: https://arxiv.org/abs/1803.11175<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html<br><br>\n",
    "**Universal Sentence Encoder (USE)** is a versatile sentence embedding model that convert sentences into vector representations. These vectors capture rich semantic information that can be used to train classifiers for a broad range of downstream tasks.\n",
    "\n",
    "![dep_nobj-1](images/USE.png)\n",
    "\n",
    "Note: USE can work on small multi sentence paragraphs.\n",
    "\n",
    "\n",
    "### High level steps for classifying text using pre-trained USE model: \n",
    "- Download Pre-trained USE Model from Tensorflow HUB<br>\n",
    "- Extract USE Repesentations for both train and test sets<br>\n",
    "- Define a the classification network architecture<br>\n",
    "- Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for USE Q&A classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process_text(input_text):\n",
    "    \"\"\"\n",
    "    Function to normalize text by applying NLP tranformations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text: String \n",
    "        Question text from the input sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String\n",
    "        pre-processed version of input string\n",
    "    \"\"\"\n",
    "    #Exercise: build multiple models based on diferrent pre-processing techniques.\n",
    "    #Un-Comment the below line to see if the model performance improves by introducing additional \n",
    "    #input_text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', input_text)\n",
    "    return input_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the raw question text and labels from the training and test dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_df['question'].to_list()\n",
    "features_test  = test_df['question'].to_list()\n",
    "labels_train   = train_df['coarse_label'].to_list()\n",
    "labels_test    = test_df['coarse_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-Process the text used for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process the text used for training and test\n",
    "features_train_processed = list(map(lambda x:pre_process_text(x), features_train))\n",
    "features_test_processed = list(map(lambda x:pre_process_text(x), features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The labels for the training and test set are in a string format (eg: ABBR, DESC etc). These labels need to be converted into a numerical set using [Scikit Learn's Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process labels for training\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels_train_tranformed = label_encoder.fit_transform(labels_train)\n",
    "labels_train_categorical = to_categorical(np.asarray(labels_train_tranformed))\n",
    "# Note: We do not have to \"fit\" the label encoder for the test set since they already have been fit on the trainset\n",
    "labels_test_transformed = label_encoder.transform(labels_test)\n",
    "labels_test_categorical = to_categorical(np.asarray(labels_test_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and load the pre-trained Universal Sentence Encoder from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "pre_trained_use_embed_model = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate sentence/phrase representations of the training and test text data using the above downloaded USE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1020 23:56:27.558945 139704171878208 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
      "I1020 23:56:33.227357 139704171878208 saver.py:1499] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embeddings_features_train = []\n",
    "embeddings_features_test = []\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings_features_train.append(session.run(pre_trained_use_embed_model(features_train_processed)))\n",
    "    embeddings_features_test.append(session.run(pre_trained_use_embed_model(features_test_processed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train = embeddings_features_train[0]\n",
    "question_embeddings_test = embeddings_features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the input embeddings\n",
    "question_embeddings_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition for USE Q&A classification\n",
    "\n",
    "We will use the [Keras Functional API Guide](https://keras.io/getting-started/functional-api-guide/#first-example-a-densely-connected-network) to build and train the USE Q&A classifier network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNAClassifier():\n",
    "    \"\"\"\n",
    "    Q&A classifier class using Keras framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name):\n",
    "        \"\"\"\n",
    "        Init function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_name: String\n",
    "            Name of the experiment. This will be used to name the model checkpoints.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #Exercise: Modify the below hyper parameters to create variations of the USE Q&A classifier model.\n",
    "        self.patience = 10\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.experiment_name = experiment_name\n",
    "        self.output_dir = 'models'\n",
    "        self.class_count = 6\n",
    "        self.model = None\n",
    "        \n",
    "        # Creating an output directory for the generated models.\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    \n",
    "    def train_vanilla_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        Simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(256, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        # Start Training\n",
    "        training_history = self.model.fit(embeddings_train, labels_train, \n",
    "                                          validation_data = (embeddings_test, labels_test),\n",
    "                                          epochs= self.epochs,\n",
    "                                          batch_size=self.batch_size,\n",
    "                                          callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history\n",
    "    \n",
    "    def train_vanilla_nn_cross_validated(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \"\"\"\n",
    "        K-Fold Cross validated simple Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        list of training history objects\n",
    "            Keras training history object. See: https://keras.io/callbacks/#history\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        # Network Architecture: Input Layer(Embeddings)-> Dense Layer -> Softmax layer\n",
    "        # Exercise: Change the size of the hidden layer and the activation unit.\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(64, activation='relu')(embedding_inputs)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        \n",
    "        training_histories = []\n",
    "        counter = 0\n",
    "        \n",
    "        #Exercise: Experiment with different number of splits.\n",
    "        kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "        for train_index, test_index in kf.split(embeddings_train):\n",
    "            \n",
    "            X_train, X_test = embeddings_train[train_index], embeddings_train[test_index]\n",
    "            y_train, y_test = labels_train[train_index], labels_train[test_index]\n",
    "            \n",
    "            model_filename = self.output_dir + \"/\" + self.experiment_name + \"_fold{}\".format(counter)\n",
    "            checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                         monitor='val_acc', verbose=1,\n",
    "                                         save_best_only=True, mode='auto')\n",
    "        \n",
    "            # Start Training\n",
    "            training_history = self.model.fit(X_train, y_train, \n",
    "                                              validation_data = (X_test, y_test),\n",
    "                                              epochs= self.epochs,\n",
    "                                              batch_size=self.batch_size,\n",
    "                                              #Exercise: Add Tensorboard here\n",
    "                                              callbacks=[checkpoint, early_stopping])\n",
    "            \n",
    "            print(\"-----------------------------\\n\")\n",
    "            print(\"KSplit {} training complete\\n\".format(counter))\n",
    "            print(\"-----------------------------\\n\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            training_histories.append(training_history)\n",
    "        \n",
    "        return training_histories\n",
    "    \n",
    "    def train_tuned_nn(self, embeddings_train, labels_train, embeddings_test, labels_test):\n",
    "        \n",
    "        \"\"\"\n",
    "        Tuned Feed forward neural network with 1 Dense layer to classify Q&A embeddings.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings_train: Numpy Array\n",
    "            USE embedding repesentation of the training set.\n",
    "            \n",
    "        labels_train: Numpy Array\n",
    "            Categorical encoded labels for the training set.\n",
    "            \n",
    "        embeddings_test: Numpy Array\n",
    "            USE embedding repesentation of the test set.\n",
    "            \n",
    "        labels_test: Numpy Array\n",
    "            Categorical encoded labels for the test set.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Keras history object\n",
    "            See: https://keras.io/callbacks/#history\n",
    "        \n",
    "        \"\"\"\n",
    "        embedding_inputs = Input(shape=(embeddings_train.shape[1],))\n",
    "        x = Dense(128, activation='relu')(embedding_inputs)\n",
    "        # Added dropouts for regularization\n",
    "        # Exercise: Change the value of dropouts.\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        predictions = Dense(self.class_count, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=embedding_inputs, outputs=predictions)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        # Keras Callbacks\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=self.patience)\n",
    "        model_filename = self.output_dir + \"/\" + self.experiment_name\n",
    "        checkpoint = ModelCheckpoint(model_filename + '.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
    "                                     monitor='val_acc', verbose=1,\n",
    "                                     save_best_only=True, mode='auto')\n",
    "        \n",
    "        \n",
    "        # Start Training\n",
    "        training_history = model.fit(embeddings_train, labels_train, \n",
    "                                     validation_data = (embeddings_test, labels_test),\n",
    "                                     epochs= self.epochs,\n",
    "                                     batch_size=self.batch_size,\n",
    "                                     #Exercise: Add Tensorboard here\n",
    "                                     callbacks=[checkpoint, early_stopping])\n",
    "        \n",
    "        return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5381 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "5381/5381 [==============================] - 11s 2ms/step - loss: 1.0667 - acc: 0.7045 - val_loss: 0.5248 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85600, saving model to models/USE_Embedding_Model.001-0.8560.hdf5\n",
      "Epoch 2/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.5500 - acc: 0.8106 - val_loss: 0.3804 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85600 to 0.86800, saving model to models/USE_Embedding_Model.002-0.8680.hdf5\n",
      "Epoch 3/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.4652 - acc: 0.8318 - val_loss: 0.3585 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86800 to 0.87000, saving model to models/USE_Embedding_Model.003-0.8700.hdf5\n",
      "Epoch 4/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.4277 - acc: 0.8441 - val_loss: 0.3226 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87000 to 0.89000, saving model to models/USE_Embedding_Model.004-0.8900.hdf5\n",
      "Epoch 5/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.4065 - acc: 0.8550 - val_loss: 0.3048 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.89000 to 0.89200, saving model to models/USE_Embedding_Model.005-0.8920.hdf5\n",
      "Epoch 6/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3917 - acc: 0.8556 - val_loss: 0.3269 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89200\n",
      "Epoch 7/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3773 - acc: 0.8614 - val_loss: 0.3039 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89200\n",
      "Epoch 8/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3709 - acc: 0.8640 - val_loss: 0.2895 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.89200 to 0.90200, saving model to models/USE_Embedding_Model.008-0.9020.hdf5\n",
      "Epoch 9/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3589 - acc: 0.8718 - val_loss: 0.2959 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90200\n",
      "Epoch 10/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3492 - acc: 0.8703 - val_loss: 0.2881 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90200\n",
      "Epoch 11/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3347 - acc: 0.8781 - val_loss: 0.2830 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.90200\n",
      "Epoch 12/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3290 - acc: 0.8799 - val_loss: 0.2809 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90200\n",
      "Epoch 13/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3168 - acc: 0.8825 - val_loss: 0.2855 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90200\n",
      "Epoch 14/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3137 - acc: 0.8829 - val_loss: 0.2875 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90200\n",
      "Epoch 15/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2983 - acc: 0.8904 - val_loss: 0.2876 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90200\n",
      "Epoch 16/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2932 - acc: 0.8946 - val_loss: 0.2713 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90200\n",
      "Epoch 17/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2843 - acc: 0.8967 - val_loss: 0.2796 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90200\n",
      "Epoch 18/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2755 - acc: 0.8989 - val_loss: 0.2781 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90200\n"
     ]
    }
   ],
   "source": [
    "# Train Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(use_embedding_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 1794 samples\n",
      "Epoch 1/100\n",
      "3587/3587 [==============================] - 11s 3ms/step - loss: 1.3899 - acc: 0.5980 - val_loss: 1.0858 - val_acc: 0.7179\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71795, saving model to models/USE_Embedding_CV_Model_fold0.001-0.7179.hdf5\n",
      "Epoch 2/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.9106 - acc: 0.7628 - val_loss: 0.7892 - val_acc: 0.7670\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71795 to 0.76700, saving model to models/USE_Embedding_CV_Model_fold0.002-0.7670.hdf5\n",
      "Epoch 3/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.6956 - acc: 0.7937 - val_loss: 0.6555 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.76700 to 0.78930, saving model to models/USE_Embedding_CV_Model_fold0.003-0.7893.hdf5\n",
      "Epoch 4/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.5867 - acc: 0.8127 - val_loss: 0.5802 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78930 to 0.80156, saving model to models/USE_Embedding_CV_Model_fold0.004-0.8016.hdf5\n",
      "Epoch 5/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.5235 - acc: 0.8227 - val_loss: 0.5481 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80156 to 0.80379, saving model to models/USE_Embedding_CV_Model_fold0.005-0.8038.hdf5\n",
      "Epoch 6/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.4826 - acc: 0.8285 - val_loss: 0.5164 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.80379 to 0.81438, saving model to models/USE_Embedding_CV_Model_fold0.006-0.8144.hdf5\n",
      "Epoch 7/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.4551 - acc: 0.8355 - val_loss: 0.5046 - val_acc: 0.8183\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81438 to 0.81828, saving model to models/USE_Embedding_CV_Model_fold0.007-0.8183.hdf5\n",
      "Epoch 8/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.4349 - acc: 0.8436 - val_loss: 0.4923 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81828\n",
      "Epoch 9/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.4173 - acc: 0.8514 - val_loss: 0.4843 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.81828 to 0.82219, saving model to models/USE_Embedding_CV_Model_fold0.009-0.8222.hdf5\n",
      "Epoch 10/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.4057 - acc: 0.8589 - val_loss: 0.4796 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82219 to 0.82664, saving model to models/USE_Embedding_CV_Model_fold0.010-0.8266.hdf5\n",
      "Epoch 11/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3960 - acc: 0.8589 - val_loss: 0.4746 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.82664\n",
      "Epoch 12/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3874 - acc: 0.8609 - val_loss: 0.4799 - val_acc: 0.8227\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82664\n",
      "Epoch 13/100\n",
      "3587/3587 [==============================] - 0s 29us/step - loss: 0.3799 - acc: 0.8634 - val_loss: 0.4692 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82664\n",
      "Epoch 14/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3731 - acc: 0.8676 - val_loss: 0.4712 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.82664 to 0.82720, saving model to models/USE_Embedding_CV_Model_fold0.014-0.8272.hdf5\n",
      "Epoch 15/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3658 - acc: 0.8662 - val_loss: 0.4818 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.82720\n",
      "Epoch 16/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3614 - acc: 0.8679 - val_loss: 0.4711 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.82720 to 0.82943, saving model to models/USE_Embedding_CV_Model_fold0.016-0.8294.hdf5\n",
      "Epoch 17/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3553 - acc: 0.8698 - val_loss: 0.4705 - val_acc: 0.8278\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82943\n",
      "Epoch 18/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3515 - acc: 0.8734 - val_loss: 0.4724 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82943\n",
      "Epoch 19/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3467 - acc: 0.8720 - val_loss: 0.4714 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82943\n",
      "Epoch 20/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3432 - acc: 0.8762 - val_loss: 0.4676 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82943\n",
      "Epoch 21/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3383 - acc: 0.8754 - val_loss: 0.4787 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82943\n",
      "Epoch 22/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3347 - acc: 0.8790 - val_loss: 0.4764 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82943\n",
      "Epoch 23/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3305 - acc: 0.8826 - val_loss: 0.4711 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.82943 to 0.83055, saving model to models/USE_Embedding_CV_Model_fold0.023-0.8305.hdf5\n",
      "Epoch 24/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3279 - acc: 0.8784 - val_loss: 0.4698 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.83055\n",
      "Epoch 25/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3230 - acc: 0.8801 - val_loss: 0.4696 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83055\n",
      "Epoch 26/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3203 - acc: 0.8807 - val_loss: 0.4715 - val_acc: 0.8278\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83055\n",
      "Epoch 27/100\n",
      "3587/3587 [==============================] - 0s 32us/step - loss: 0.3172 - acc: 0.8849 - val_loss: 0.4765 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83055\n",
      "Epoch 28/100\n",
      "3587/3587 [==============================] - 0s 32us/step - loss: 0.3146 - acc: 0.8829 - val_loss: 0.4693 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83055\n",
      "Epoch 29/100\n",
      "3587/3587 [==============================] - 0s 32us/step - loss: 0.3116 - acc: 0.8868 - val_loss: 0.4763 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83055\n",
      "Epoch 30/100\n",
      "3587/3587 [==============================] - 0s 32us/step - loss: 0.3069 - acc: 0.8857 - val_loss: 0.4761 - val_acc: 0.8278\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.83055\n",
      "Epoch 31/100\n",
      "3587/3587 [==============================] - 0s 32us/step - loss: 0.3035 - acc: 0.8868 - val_loss: 0.4839 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83055\n",
      "Epoch 32/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3006 - acc: 0.8874 - val_loss: 0.4722 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83055\n",
      "Epoch 33/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.2984 - acc: 0.8921 - val_loss: 0.4804 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.83055\n",
      "-----------------------------\n",
      "\n",
      "KSplit 0 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Train on 3587 samples, validate on 1794 samples\n",
      "Epoch 1/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3762 - acc: 0.8651 - val_loss: 0.3129 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88462, saving model to models/USE_Embedding_CV_Model_fold1.001-0.8846.hdf5\n",
      "Epoch 2/100\n",
      "3587/3587 [==============================] - 0s 29us/step - loss: 0.3609 - acc: 0.8693 - val_loss: 0.3110 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88462 to 0.89186, saving model to models/USE_Embedding_CV_Model_fold1.002-0.8919.hdf5\n",
      "Epoch 3/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3530 - acc: 0.8695 - val_loss: 0.3177 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89186\n",
      "Epoch 4/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3466 - acc: 0.8740 - val_loss: 0.3248 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89186\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3396 - acc: 0.8729 - val_loss: 0.3323 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89186\n",
      "Epoch 6/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3317 - acc: 0.8796 - val_loss: 0.3346 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89186\n",
      "Epoch 7/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3283 - acc: 0.8768 - val_loss: 0.3390 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89186\n",
      "Epoch 8/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3235 - acc: 0.8826 - val_loss: 0.3476 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89186\n",
      "Epoch 9/100\n",
      "3587/3587 [==============================] - 0s 29us/step - loss: 0.3194 - acc: 0.8812 - val_loss: 0.3519 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89186\n",
      "Epoch 10/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3155 - acc: 0.8846 - val_loss: 0.3471 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89186\n",
      "Epoch 11/100\n",
      "3587/3587 [==============================] - 0s 31us/step - loss: 0.3111 - acc: 0.8876 - val_loss: 0.3512 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89186\n",
      "Epoch 12/100\n",
      "3587/3587 [==============================] - 0s 30us/step - loss: 0.3079 - acc: 0.8890 - val_loss: 0.3541 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89186\n",
      "-----------------------------\n",
      "\n",
      "KSplit 1 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Train on 3588 samples, validate on 1793 samples\n",
      "Epoch 1/100\n",
      "3588/3588 [==============================] - 0s 30us/step - loss: 0.3488 - acc: 0.8740 - val_loss: 0.2643 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90463, saving model to models/USE_Embedding_CV_Model_fold2.001-0.9046.hdf5\n",
      "Epoch 2/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.3382 - acc: 0.8763 - val_loss: 0.2714 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90463\n",
      "Epoch 3/100\n",
      "3588/3588 [==============================] - 0s 32us/step - loss: 0.3285 - acc: 0.8776 - val_loss: 0.2769 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90463\n",
      "Epoch 4/100\n",
      "3588/3588 [==============================] - 0s 32us/step - loss: 0.3220 - acc: 0.8838 - val_loss: 0.2791 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90463\n",
      "Epoch 5/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.3153 - acc: 0.8829 - val_loss: 0.2794 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90463\n",
      "Epoch 6/100\n",
      "3588/3588 [==============================] - 0s 32us/step - loss: 0.3109 - acc: 0.8877 - val_loss: 0.2891 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90463\n",
      "Epoch 7/100\n",
      "3588/3588 [==============================] - 0s 32us/step - loss: 0.3068 - acc: 0.8874 - val_loss: 0.2969 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90463\n",
      "Epoch 8/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.3008 - acc: 0.8880 - val_loss: 0.2960 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90463\n",
      "Epoch 9/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.2981 - acc: 0.8905 - val_loss: 0.3005 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90463\n",
      "Epoch 10/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.2938 - acc: 0.8919 - val_loss: 0.3041 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90463\n",
      "Epoch 11/100\n",
      "3588/3588 [==============================] - 0s 31us/step - loss: 0.2913 - acc: 0.8958 - val_loss: 0.3004 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.90463\n",
      "-----------------------------\n",
      "\n",
      "KSplit 2 training complete\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Cross Validated Vanilla Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_classifier = QNAClassifier(\"USE_Embedding_CV_Model\")\n",
    "use_embedding_training_history = use_embedding_classifier.train_vanilla_nn_cross_validated(question_embeddings_train, labels_train_categorical,\n",
    "                                                                                           question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5381 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "5381/5381 [==============================] - 12s 2ms/step - loss: 1.1910 - acc: 0.5774 - val_loss: 0.4969 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85400, saving model to models/USE_Embedding_Tuned_Model.001-0.8540.hdf5\n",
      "Epoch 2/100\n",
      "5381/5381 [==============================] - 0s 37us/step - loss: 0.6157 - acc: 0.7837 - val_loss: 0.4012 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85400 to 0.87000, saving model to models/USE_Embedding_Tuned_Model.002-0.8700.hdf5\n",
      "Epoch 3/100\n",
      "5381/5381 [==============================] - 0s 37us/step - loss: 0.5278 - acc: 0.8160 - val_loss: 0.3442 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87000 to 0.87400, saving model to models/USE_Embedding_Tuned_Model.003-0.8740.hdf5\n",
      "Epoch 4/100\n",
      "5381/5381 [==============================] - 0s 37us/step - loss: 0.4952 - acc: 0.8175 - val_loss: 0.3164 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87400 to 0.88400, saving model to models/USE_Embedding_Tuned_Model.004-0.8840.hdf5\n",
      "Epoch 5/100\n",
      "5381/5381 [==============================] - 0s 38us/step - loss: 0.4490 - acc: 0.8359 - val_loss: 0.3314 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88400\n",
      "Epoch 6/100\n",
      "5381/5381 [==============================] - 0s 38us/step - loss: 0.4400 - acc: 0.8428 - val_loss: 0.3028 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88400 to 0.89800, saving model to models/USE_Embedding_Tuned_Model.006-0.8980.hdf5\n",
      "Epoch 7/100\n",
      "5381/5381 [==============================] - 0s 38us/step - loss: 0.4225 - acc: 0.8536 - val_loss: 0.2978 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89800\n",
      "Epoch 8/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.4015 - acc: 0.8547 - val_loss: 0.3014 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89800\n",
      "Epoch 9/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3944 - acc: 0.8589 - val_loss: 0.2845 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.89800 to 0.90400, saving model to models/USE_Embedding_Tuned_Model.009-0.9040.hdf5\n",
      "Epoch 10/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3783 - acc: 0.8647 - val_loss: 0.2827 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90400\n",
      "Epoch 11/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3639 - acc: 0.8664 - val_loss: 0.2982 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.90400\n",
      "Epoch 12/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3472 - acc: 0.8734 - val_loss: 0.2800 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90400\n",
      "Epoch 13/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.3335 - acc: 0.8757 - val_loss: 0.2874 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90400\n",
      "Epoch 14/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3200 - acc: 0.8842 - val_loss: 0.2875 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90400\n",
      "Epoch 15/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3233 - acc: 0.8805 - val_loss: 0.2707 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.90400 to 0.90800, saving model to models/USE_Embedding_Tuned_Model.015-0.9080.hdf5\n",
      "Epoch 16/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.3036 - acc: 0.8889 - val_loss: 0.2789 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90800\n",
      "Epoch 17/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2970 - acc: 0.8844 - val_loss: 0.2749 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90800\n",
      "Epoch 18/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2922 - acc: 0.8920 - val_loss: 0.2686 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90800\n",
      "Epoch 19/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2756 - acc: 0.9019 - val_loss: 0.2763 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90800\n",
      "Epoch 20/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2703 - acc: 0.9009 - val_loss: 0.2843 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90800\n",
      "Epoch 21/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2598 - acc: 0.9056 - val_loss: 0.2624 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.90800 to 0.91200, saving model to models/USE_Embedding_Tuned_Model.021-0.9120.hdf5\n",
      "Epoch 22/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2514 - acc: 0.9097 - val_loss: 0.2686 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.91200\n",
      "Epoch 23/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.2410 - acc: 0.9149 - val_loss: 0.2729 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.91200\n",
      "Epoch 24/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2250 - acc: 0.9160 - val_loss: 0.2720 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.91200\n",
      "Epoch 25/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2218 - acc: 0.9167 - val_loss: 0.2786 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.91200\n",
      "Epoch 26/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2193 - acc: 0.9205 - val_loss: 0.2900 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.91200\n",
      "Epoch 27/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2027 - acc: 0.9299 - val_loss: 0.2812 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.91200\n",
      "Epoch 28/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.1982 - acc: 0.9283 - val_loss: 0.2737 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.91200\n",
      "Epoch 29/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.2081 - acc: 0.9195 - val_loss: 0.2849 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.91200\n",
      "Epoch 30/100\n",
      "5381/5381 [==============================] - 0s 39us/step - loss: 0.1964 - acc: 0.9262 - val_loss: 0.2669 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.91200\n",
      "Epoch 31/100\n",
      "5381/5381 [==============================] - 0s 40us/step - loss: 0.1858 - acc: 0.9325 - val_loss: 0.2831 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.91200\n"
     ]
    }
   ],
   "source": [
    "# Train Tuned Neural Network with Pre-trained USE Embeddings\n",
    "use_embedding_tuned_classifier = QNAClassifier(\"USE_Embedding_Tuned_Model\")\n",
    "use_embedding_tuned_training_history = use_embedding_tuned_classifier.train_tuned_nn(question_embeddings_train, labels_train_categorical,\n",
    "                                                                          question_embeddings_test, labels_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training history of above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(use_embedding_tuned_training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the test classification metrics for the above Tuned Neural Network with Pre-trained USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.89      0.94         9\n",
      "        DESC       0.91      0.91      0.91       138\n",
      "        ENTY       0.83      0.82      0.82        94\n",
      "         HUM       0.94      0.97      0.95        65\n",
      "         LOC       0.97      0.90      0.94        81\n",
      "         NUM       0.93      0.97      0.95       113\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.93      0.91      0.92       500\n",
      "weighted avg       0.91      0.91      0.91       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: Please use the appropriate model path corresponding to your training step.\n",
    "print(generate_classification_report(model_path = 'models/USE_Embedding_Tuned_Model.011-0.9140.hdf5', \n",
    "                                     label_encoder = label_encoder,\n",
    "                                     test_features = question_embeddings_test,\n",
    "                                     test_labels = labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT: Bidirectional Encoder Representation from Transformers \n",
    "<u>Refrence Paper</u>: https://arxiv.org/abs/1810.04805<br>\n",
    "<u>Announcement</u>: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n",
    "\n",
    "**BERT** is the current state of the art Language Model and is designed by pre-training deep bidirectional representations from unlabeled(Wikipedia)text by jointly conditioning on both left and right context in all layers.\n",
    "BERT’s model architecture is a multi-layer/stacked set of bidirectional Transformers with the following 2 variants:\n",
    "**BERTBASE** (L=12, H=768, A=12, Total Parameters=110M) and **BERTLARGE** (L=24, H=1024, A=16, Total Parameters=340M).\n",
    "\n",
    "![dep_nobj-1](images/BERT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Data Prep for BERT Q&A classification</h3>\n",
    "\n",
    "Since BERT is a pre-trained Langauage Model, fine-tuning tasks using BERT is expected to have the same input format of data as that of BERT's training. In a nutshell, we'll have to apply the following transformations to our input text to conform to BERT's fine tuning input expectation.\n",
    "    \n",
    "- Lowercase our text (if we're using a BERT lowercase model)<br>\n",
    "- Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])<br>\n",
    "- Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])<br>\n",
    "- Map our words to indexes using a vocab file that BERT provides<br>\n",
    "- Add special \"CLS\" and \"SEP\" tokens for NextSentenceIdentication (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n",
    "- Append \"index\" and \"segment\" tokens to each input (see the Section 3 https://arxiv.org/pdf/1810.04805.pdf)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT Imports: BERT Classification\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fortunately, there are multiple libraries that'll trannsform our raw Question text to a format that BERT understands\n",
    "**bert.run_classifier.InputExample** is a data structure that will store the tranformed Quesstion text into BERT Input format. The below lambda section is only initializing these BERT Input format data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_train, labels_train))\n",
    "test_InputSamples = list(map(lambda x,y: bert.run_classifier.InputExample(guid=None, text_a=x, text_b=None, label=y),\n",
    "                              features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download the pre-trained BERT base model and load up the BERT tokenizers to operate on our transformed Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1020 23:58:37.155352 139704171878208 saver.py:1499] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"\n",
    "    Load the pre-trained BERT model and extract the vocab file and tokenizer from TF HUB\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BERT tokenizer object: bert.tokenization.FullTokenizer\n",
    "        See: https://github.com/google-research/bert/blob/master/tokenization.py\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time to run the pre-trained BERT tokenizer on our input Question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1020 23:58:37.776691 139704171878208 run_classifier.py:774] Writing example 0 of 5381\n",
      "I1020 23:58:37.777919 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:37.778488 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:37.779036 139704171878208 run_classifier.py:464] tokens: [CLS] how did ser ##f ##dom develop in and then leave russia ? [SEP]\n",
      "I1020 23:58:37.779569 139704171878208 run_classifier.py:465] input_ids: 101 2129 2106 14262 2546 9527 4503 1999 1998 2059 2681 3607 1029 102 0 0 0 0 0 0\n",
      "I1020 23:58:37.780084 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "I1020 23:58:37.780637 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.782909 139704171878208 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1020 23:58:37.783759 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:37.784299 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:37.784969 139704171878208 run_classifier.py:464] tokens: [CLS] what films featured the character pope ##ye doyle ? [SEP]\n",
      "I1020 23:58:37.785483 139704171878208 run_classifier.py:465] input_ids: 101 2054 3152 2956 1996 2839 4831 6672 11294 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.785995 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.786522 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.787022 139704171878208 run_classifier.py:468] label: ENTY (id = 2)\n",
      "I1020 23:58:37.787745 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:37.788261 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:37.788789 139704171878208 run_classifier.py:464] tokens: [CLS] how can i find a list of celebrities ' real names ? [SEP]\n",
      "I1020 23:58:37.789331 139704171878208 run_classifier.py:465] input_ids: 101 2129 2064 1045 2424 1037 2862 1997 12330 1005 2613 3415 1029 102 0 0 0 0 0 0\n",
      "I1020 23:58:37.789845 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "I1020 23:58:37.790396 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.790893 139704171878208 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1020 23:58:37.791676 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:37.792218 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:37.792740 139704171878208 run_classifier.py:464] tokens: [CLS] what f ##ow ##l grabs the spotlight after the chinese year of the monkey ? [SEP]\n",
      "I1020 23:58:37.793452 139704171878208 run_classifier.py:465] input_ids: 101 2054 1042 5004 2140 13273 1996 17763 2044 1996 2822 2095 1997 1996 10608 1029 102 0 0 0\n",
      "I1020 23:58:37.793962 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "I1020 23:58:37.794474 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.794984 139704171878208 run_classifier.py:468] label: ENTY (id = 2)\n",
      "I1020 23:58:37.795668 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:37.796167 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:37.796673 139704171878208 run_classifier.py:464] tokens: [CLS] what is the full form of . com ? [SEP]\n",
      "I1020 23:58:37.797180 139704171878208 run_classifier.py:465] input_ids: 101 2054 2003 1996 2440 2433 1997 1012 4012 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.797688 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.798224 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:37.798750 139704171878208 run_classifier.py:468] label: ABBR (id = 5)\n",
      "I1020 23:58:38.850954 139704171878208 run_classifier.py:774] Writing example 0 of 500\n",
      "I1020 23:58:38.851894 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:38.852505 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:38.852980 139704171878208 run_classifier.py:464] tokens: [CLS] how far is it from denver to aspen ? [SEP]\n",
      "I1020 23:58:38.853599 139704171878208 run_classifier.py:465] input_ids: 101 2129 2521 2003 2009 2013 7573 2000 18567 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.854465 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.854981 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.855499 139704171878208 run_classifier.py:468] label: NUM (id = 0)\n",
      "I1020 23:58:38.856201 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:38.856750 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:38.857588 139704171878208 run_classifier.py:464] tokens: [CLS] what county is modest ##o , california in ? [SEP]\n",
      "I1020 23:58:38.858073 139704171878208 run_classifier.py:465] input_ids: 101 2054 2221 2003 10754 2080 1010 2662 1999 1029 102 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.858631 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.859132 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.859642 139704171878208 run_classifier.py:468] label: LOC (id = 4)\n",
      "I1020 23:58:38.860250 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:38.860773 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:38.861292 139704171878208 run_classifier.py:464] tokens: [CLS] who was galileo ? [SEP]\n",
      "I1020 23:58:38.861806 139704171878208 run_classifier.py:465] input_ids: 101 2040 2001 21514 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.862356 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.862900 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.863400 139704171878208 run_classifier.py:468] label: HUM (id = 3)\n",
      "I1020 23:58:38.864045 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:38.864746 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:38.865215 139704171878208 run_classifier.py:464] tokens: [CLS] what is an atom ? [SEP]\n",
      "I1020 23:58:38.865769 139704171878208 run_classifier.py:465] input_ids: 101 2054 2003 2019 13787 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.866302 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.866851 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.867384 139704171878208 run_classifier.py:468] label: DESC (id = 1)\n",
      "I1020 23:58:38.868046 139704171878208 run_classifier.py:461] *** Example ***\n",
      "I1020 23:58:38.868554 139704171878208 run_classifier.py:462] guid: None\n",
      "I1020 23:58:38.869062 139704171878208 run_classifier.py:464] tokens: [CLS] when did hawaii become a state ? [SEP]\n",
      "I1020 23:58:38.869589 139704171878208 run_classifier.py:465] input_ids: 101 2043 2106 7359 2468 1037 2110 1029 102 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.870115 139704171878208 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.870639 139704171878208 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1020 23:58:38.871147 139704171878208 run_classifier.py:468] label: NUM (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# This is the max length of tokens in our Question text dataset\n",
    "# Exercise: Modify this MAX_SEQ_LENGTH value to see how it affects the training process\n",
    "MAX_SEQ_LENGTH = 20\n",
    "label_list = list(set(labels_train))\n",
    "\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputSamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Definition for BERT Q&A classification\n",
    "\n",
    "We'll use Tensorflow's Estimator API/Framework to train our fine-tuned BERT Q&A classification network. See https://www.tensorflow.org/guide/estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "    \"\"\"\n",
    "    Our Custom fine-tuning Q&A classifier definition using BERT output layers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    is_predicting: boolean\n",
    "        Boolean variable to indicate Training or Prediction mode.\n",
    "\n",
    "    input_ids: Numpy Array\n",
    "        BERT vocab token index for the input sample.\n",
    "\n",
    "    input_mask: Numpy Array\n",
    "        Flag to indicate if the input token is masked (1: Yes, 0:No).\n",
    "\n",
    "    segment_ids: Numpy Array\n",
    "        Flag to indicate which sentence the token belongs to. (0: 1st sentence, 1:2nd sentence).\n",
    "        \n",
    "    labels: Numpy Array\n",
    "        Classification label for the input.\n",
    "        \n",
    "    num_labels: integer\n",
    "        Total number of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    In Training Mode return (Training Loss, Evaluation Labels, Evaluation probs per sample) tuple\n",
    "    In Prediction Mode return (Evaluation Labels, Evaluation probs per sample) tuple\n",
    "\n",
    "    \"\"\"\n",
    "    bert_module = hub.Module( BERT_MODEL_HUB,trainable=True)\n",
    "    bert_inputs = dict( input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Tunable layer.\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],\n",
    "                                     initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimator driver logic for Training, Evaluation and Predict modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"\n",
    "    Estimator driver logic for Training, Evaluation and Predict modes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_labels : integer\n",
    "        Total number of labels\n",
    "        \n",
    "    learning_rate : float\n",
    "        Learning rate for underlying neural network\n",
    "        \n",
    "    num_train_steps: integer\n",
    "        Number of steps to train (Sample Size/(Batch Size*Number of Epochs))\n",
    "        \n",
    "    num_warmup_steps: float\n",
    "        Dynamic learning rate adjustment proportion\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model_fn closure: Python Object\n",
    "        Returns a closure of the driver logic\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        \"\"\"\n",
    "        Definition for Training, Evaluation and Predict modes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features: Dictionary\n",
    "            Training/Test features\n",
    "            \n",
    "        labels: Numpy Array\n",
    "            Train/Test labels\n",
    "            \n",
    "        mode: Numpy Array\n",
    "            Train/Eval/Predict\n",
    "            \n",
    "        params: Dictionary\n",
    "            Dict with training hyperparams\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        EstimatorSpec: tf.estimator.EstimatorSpec\n",
    "            https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            # Get BERT model definition\n",
    "            (loss, predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics.\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                \"\"\"\n",
    "                Function to calculate training/evaluation metrics\n",
    "                \"\"\"\n",
    "                \n",
    "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "                \n",
    "                return {\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = bert_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Modify the below values and observe the change in the training process\n",
    "# Compute train and warmup steps from batch size\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 10\n",
    "SAVE_SUMMARY_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir='models',\n",
    "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "                                    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1020 23:58:38.993506 139704171878208 estimator.py:209] Using config: {'_model_dir': 'models', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0c6828b7f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(num_labels=len(label_list), learning_rate=LEARNING_RATE,\n",
    "                            num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder( features=train_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                      is_training=True, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1021 00:01:52.274090 139704171878208 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1021 00:01:52.790899 139704171878208 estimator.py:1145] Calling model_fn.\n",
      "I1021 00:01:56.310527 139704171878208 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "I1021 00:02:05.976285 139704171878208 estimator.py:1147] Done calling model_fn.\n",
      "I1021 00:02:05.978904 139704171878208 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I1021 00:02:09.818846 139704171878208 monitored_session.py:240] Graph was finalized.\n",
      "I1021 00:02:14.325299 139704171878208 session_manager.py:500] Running local_init_op.\n",
      "I1021 00:02:14.633926 139704171878208 session_manager.py:502] Done running local_init_op.\n",
      "I1021 00:02:23.863315 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 0 into models/model.ckpt.\n",
      "I1021 00:02:35.703777 139704171878208 basic_session_run_hooks.py:262] loss = 1.8792443, step = 1\n",
      "I1021 00:02:56.933883 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 10 into models/model.ckpt.\n",
      "I1021 00:03:22.217900 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 20 into models/model.ckpt.\n",
      "I1021 00:03:40.844120 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 30 into models/model.ckpt.\n",
      "I1021 00:03:59.408563 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 40 into models/model.ckpt.\n",
      "I1021 00:04:18.232782 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 50 into models/model.ckpt.\n",
      "W1021 00:04:19.605679 139704171878208 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "I1021 00:04:37.865327 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 60 into models/model.ckpt.\n",
      "I1021 00:04:56.958139 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 70 into models/model.ckpt.\n",
      "I1021 00:05:15.895488 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 80 into models/model.ckpt.\n",
      "I1021 00:05:34.984364 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 90 into models/model.ckpt.\n",
      "W1021 00:05:40.957823 139704171878208 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 91 vs previous value: 91. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1021 00:05:54.038923 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 100 into models/model.ckpt.\n",
      "I1021 00:06:04.890853 139704171878208 basic_session_run_hooks.py:692] global_step/sec: 0.47804\n",
      "I1021 00:06:04.891821 139704171878208 basic_session_run_hooks.py:260] loss = 0.2495918, step = 101 (209.188 sec)\n",
      "I1021 00:06:19.584069 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 110 into models/model.ckpt.\n",
      "I1021 00:06:38.548229 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 120 into models/model.ckpt.\n",
      "I1021 00:06:57.397050 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 130 into models/model.ckpt.\n",
      "I1021 00:07:16.496736 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 140 into models/model.ckpt.\n",
      "I1021 00:07:35.722585 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 150 into models/model.ckpt.\n",
      "I1021 00:07:55.041064 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 160 into models/model.ckpt.\n",
      "I1021 00:08:14.125098 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 170 into models/model.ckpt.\n",
      "I1021 00:08:33.233553 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 180 into models/model.ckpt.\n",
      "I1021 00:08:52.079800 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 190 into models/model.ckpt.\n",
      "I1021 00:09:11.069355 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 200 into models/model.ckpt.\n",
      "I1021 00:09:15.387121 139704171878208 basic_session_run_hooks.py:692] global_step/sec: 0.524945\n",
      "I1021 00:09:15.388061 139704171878208 basic_session_run_hooks.py:260] loss = 0.064966775, step = 201 (190.496 sec)\n",
      "I1021 00:09:30.168951 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 210 into models/model.ckpt.\n",
      "I1021 00:09:49.211436 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 220 into models/model.ckpt.\n",
      "I1021 00:10:08.141078 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 230 into models/model.ckpt.\n",
      "I1021 00:10:27.132670 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 240 into models/model.ckpt.\n",
      "I1021 00:10:45.911091 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 250 into models/model.ckpt.\n",
      "I1021 00:11:04.892364 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 260 into models/model.ckpt.\n",
      "I1021 00:11:24.045709 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 270 into models/model.ckpt.\n",
      "I1021 00:11:43.097114 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 280 into models/model.ckpt.\n",
      "I1021 00:12:02.026645 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 290 into models/model.ckpt.\n",
      "I1021 00:12:21.152182 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 300 into models/model.ckpt.\n",
      "I1021 00:12:25.697412 139704171878208 basic_session_run_hooks.py:692] global_step/sec: 0.525458\n",
      "I1021 00:12:25.698399 139704171878208 basic_session_run_hooks.py:260] loss = 0.07119317, step = 301 (190.310 sec)\n",
      "I1021 00:12:40.359567 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 310 into models/model.ckpt.\n",
      "I1021 00:12:59.505412 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 320 into models/model.ckpt.\n",
      "I1021 00:13:18.521575 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 330 into models/model.ckpt.\n",
      "I1021 00:13:37.423883 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 340 into models/model.ckpt.\n",
      "I1021 00:13:56.321564 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 350 into models/model.ckpt.\n",
      "I1021 00:14:15.250697 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 360 into models/model.ckpt.\n",
      "I1021 00:14:34.255733 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 370 into models/model.ckpt.\n",
      "I1021 00:14:53.177366 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 380 into models/model.ckpt.\n",
      "I1021 00:15:12.083275 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 390 into models/model.ckpt.\n",
      "I1021 00:15:31.145691 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 400 into models/model.ckpt.\n",
      "I1021 00:15:35.440285 139704171878208 basic_session_run_hooks.py:692] global_step/sec: 0.527029\n",
      "I1021 00:15:35.441376 139704171878208 basic_session_run_hooks.py:260] loss = 0.00987707, step = 401 (189.743 sec)\n",
      "I1021 00:15:50.102003 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 410 into models/model.ckpt.\n",
      "I1021 00:16:09.067125 139704171878208 basic_session_run_hooks.py:606] Saving checkpoints for 420 into models/model.ckpt.\n",
      "I1021 00:16:12.120735 139704171878208 estimator.py:368] Loss for final step: 0.012505842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Training\n"
     ]
    }
   ],
   "source": [
    "print('Start Training')\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"End Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the training metrics on the Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "!tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(features=test_features, seq_length=MAX_SEQ_LENGTH,\n",
    "                                                is_training=False, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1021 00:16:21.092340 139704171878208 estimator.py:1145] Calling model_fn.\n",
      "I1021 00:16:24.628030 139704171878208 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "I1021 00:16:34.409988 139704171878208 estimator.py:1147] Done calling model_fn.\n",
      "I1021 00:16:34.432067 139704171878208 evaluation.py:255] Starting evaluation at 2019-10-21T00:16:34Z\n",
      "I1021 00:16:35.933473 139704171878208 monitored_session.py:240] Graph was finalized.\n",
      "I1021 00:16:35.936528 139704171878208 saver.py:1280] Restoring parameters from models/model.ckpt-420\n",
      "I1021 00:16:39.020625 139704171878208 session_manager.py:500] Running local_init_op.\n",
      "I1021 00:16:39.333652 139704171878208 session_manager.py:502] Done running local_init_op.\n",
      "I1021 00:16:45.428935 139704171878208 evaluation.py:275] Finished evaluation at 2019-10-21-00:16:45\n",
      "I1021 00:16:45.429843 139704171878208 estimator.py:2039] Saving dict for global step 420: false_negatives = 2.0, false_positives = 0.0, global_step = 420, loss = 0.122957096, precision = 1.0, recall = 0.99483204, true_negatives = 113.0, true_positives = 385.0\n",
      "I1021 00:16:45.430671 139704171878208 estimator.py:2099] Saving 'checkpoint_path' summary for global step 420: models/model.ckpt-420\n"
     ]
    }
   ],
   "source": [
    "metrics = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "metrics[\"accuracy\"] = (metrics[\"true_positives\"] + metrics[\"true_negatives\"])/(metrics[\"true_positives\"] + metrics[\"true_negatives\"]+metrics[\"false_positives\"] + metrics[\"false_negatives\"])\n",
    "metrics[\"f1_score\"] = (2*metrics[\"precision\"]*metrics[\"recall\"])/(metrics[\"precision\"]+metrics[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false_negatives': 2.0,\n",
       " 'false_positives': 0.0,\n",
       " 'loss': 0.122957096,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.99483204,\n",
       " 'true_negatives': 113.0,\n",
       " 'true_positives': 385.0,\n",
       " 'global_step': 420,\n",
       " 'accuracy': 0.996,\n",
       " 'f1_score': 0.9974093251863407}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "Performance of BERT on various tasks\n",
    "\n",
    "![dep_nobj-1](images/Conclusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Universal Sentence Encoder: https://arxiv.org/abs/1803.11175\n",
    "- Tensorflow Estimator: https://www.tensorflow.org/guide/estimator\n",
    "- BERT: https://arxiv.org/abs/1810.04805"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
